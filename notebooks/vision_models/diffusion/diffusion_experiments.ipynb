{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Diffusion Model Experiments for Genomic Structural Variants\n",
        "\n",
        "Experimental Design:\n",
        "- Instances 1-3: Architecture optimization (U-Net Small/Medium/Large)\n",
        "- Instances 4-7: Noise schedule optimization (Standard/Low/High/Fast)\n",
        "- Instance 8: Evaluation strategy optimization\n",
        "- Instance 9: Final model training with best configuration"
      ],
      "metadata": {
        "id": "Xg0bom454bXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from scipy.stats import ttest_rel\n",
        "import copy\n",
        "from itertools import product\n",
        "import glob\n",
        "import warnings\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import shutil\n",
        "import time\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "DATA_DIR = '../data/processed/all_datasets_images_rgb'\n",
        "SAVE_DIR = '../data/processed/experiment_results'\n",
        "FIGURES_DIR = '../figures'\n",
        "\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")"
      ],
      "metadata": {
        "id": "tuKs7aQB4mee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiffusionSchedule:\n",
        "    \"\"\"Noise scheduling for diffusion process\"\"\"\n",
        "    def __init__(self, timesteps=1000, beta_start=0.0001, beta_end=0.02):\n",
        "        self.timesteps = timesteps\n",
        "        self.betas = torch.linspace(beta_start, beta_end, timesteps)\n",
        "        self.alphas = 1.0 - self.betas\n",
        "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
        "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
        "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n",
        "\n",
        "    def q_sample(self, x_start, t, noise=None):\n",
        "        \"\"\"Forward diffusion process\"\"\"\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x_start)\n",
        "        sqrt_alphas_cumprod_t = self.sqrt_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
        "        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
        "        return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise\n",
        "\n",
        "    def to(self, device):\n",
        "        for attr in ['betas', 'alphas', 'alphas_cumprod', 'sqrt_alphas_cumprod', 'sqrt_one_minus_alphas_cumprod']:\n",
        "            setattr(self, attr, getattr(self, attr).to(device))\n",
        "        return self\n",
        "\n",
        "class TimeEmbedding(nn.Module):\n",
        "    \"\"\"Sinusoidal time embeddings for diffusion timesteps\"\"\"\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = torch.log(torch.tensor(10000.0)) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    \"\"\"Residual block with time conditioning\"\"\"\n",
        "    def __init__(self, in_ch, out_ch, time_dim=128):\n",
        "        super().__init__()\n",
        "        self.time_mlp = nn.Linear(time_dim, out_ch)\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
        "        self.norm1 = nn.GroupNorm(8, out_ch)\n",
        "        self.norm2 = nn.GroupNorm(8, out_ch)\n",
        "        self.residual_conv = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
        "\n",
        "    def forward(self, x, time_emb):\n",
        "        h = self.norm1(self.conv1(x))\n",
        "        h = F.relu(h)\n",
        "        time_emb = self.time_mlp(time_emb)\n",
        "        h = h + time_emb[:, :, None, None]\n",
        "        h = self.norm2(self.conv2(h))\n",
        "        h = F.relu(h)\n",
        "        return h + self.residual_conv(x)\n",
        "\n",
        "class UNetSmall(nn.Module):\n",
        "    \"\"\"Small U-Net for fast training\"\"\"\n",
        "    def __init__(self, in_channels=3, out_channels=3, time_dim=64):\n",
        "        super().__init__()\n",
        "        self.time_embedding = TimeEmbedding(time_dim)\n",
        "        self.conv_in = nn.Conv2d(in_channels, 32, 3, padding=1)\n",
        "        self.down1 = ResBlock(32, 32, time_dim)\n",
        "        self.down2 = ResBlock(32, 64, time_dim)\n",
        "        self.down3 = ResBlock(64, 128, time_dim)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.bottleneck = ResBlock(128, 128, time_dim)\n",
        "        self.up3 = ResBlock(128 + 128, 64, time_dim)\n",
        "        self.up2 = ResBlock(64 + 64, 32, time_dim)\n",
        "        self.up1 = ResBlock(32 + 32, 32, time_dim)\n",
        "        self.conv_out = nn.Conv2d(32, out_channels, 3, padding=1)\n",
        "\n",
        "    def forward(self, x, timestep):\n",
        "        time_emb = self.time_embedding(timestep)\n",
        "        # Encoder\n",
        "        x1 = F.relu(self.conv_in(x))\n",
        "        x1 = self.down1(x1, time_emb)\n",
        "        x2 = self.pool(x1)\n",
        "        x2 = self.down2(x2, time_emb)\n",
        "        x3 = self.pool(x2)\n",
        "        x3 = self.down3(x3, time_emb)\n",
        "        # Bottleneck\n",
        "        x_bottle = self.pool(x3)\n",
        "        x_bottle = self.bottleneck(x_bottle, time_emb)\n",
        "        # Decoder\n",
        "        x = F.interpolate(x_bottle, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = torch.cat([x, x3], dim=1)\n",
        "        x = self.up3(x, time_emb)\n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = torch.cat([x, x2], dim=1)\n",
        "        x = self.up2(x, time_emb)\n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = torch.cat([x, x1], dim=1)\n",
        "        x = self.up1(x, time_emb)\n",
        "        return self.conv_out(x)\n",
        "\n",
        "class UNetMedium(nn.Module):\n",
        "    \"\"\"Medium U-Net (balanced approach)\"\"\"\n",
        "    def __init__(self, in_channels=3, out_channels=3, time_dim=128):\n",
        "        super().__init__()\n",
        "        self.time_embedding = TimeEmbedding(time_dim)\n",
        "        self.conv_in = nn.Conv2d(in_channels, 64, 3, padding=1)\n",
        "        self.down1 = ResBlock(64, 64, time_dim)\n",
        "        self.down2 = ResBlock(64, 128, time_dim)\n",
        "        self.down3 = ResBlock(128, 256, time_dim)\n",
        "        self.down4 = ResBlock(256, 512, time_dim)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.bottleneck = ResBlock(512, 512, time_dim)\n",
        "        self.up4 = ResBlock(512 + 512, 256, time_dim)\n",
        "        self.up3 = ResBlock(256 + 256, 128, time_dim)\n",
        "        self.up2 = ResBlock(128 + 128, 64, time_dim)\n",
        "        self.up1 = ResBlock(64 + 64, 64, time_dim)\n",
        "        self.conv_out = nn.Conv2d(64, out_channels, 3, padding=1)\n",
        "\n",
        "    def forward(self, x, timestep):\n",
        "        time_emb = self.time_embedding(timestep)\n",
        "        # Encoder\n",
        "        x1 = F.relu(self.conv_in(x))\n",
        "        x1 = self.down1(x1, time_emb)\n",
        "        x2 = self.pool(x1)\n",
        "        x2 = self.down2(x2, time_emb)\n",
        "        x3 = self.pool(x2)\n",
        "        x3 = self.down3(x3, time_emb)\n",
        "        x4 = self.pool(x3)\n",
        "        x4 = self.down4(x4, time_emb)\n",
        "        # Bottleneck\n",
        "        x_bottle = self.pool(x4)\n",
        "        x_bottle = self.bottleneck(x_bottle, time_emb)\n",
        "        # Decoder\n",
        "        x = F.interpolate(x_bottle, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = torch.cat([x, x4], dim=1)\n",
        "        x = self.up4(x, time_emb)\n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = torch.cat([x, x3], dim=1)\n",
        "        x = self.up3(x, time_emb)\n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = torch.cat([x, x2], dim=1)\n",
        "        x = self.up2(x, time_emb)\n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = torch.cat([x, x1], dim=1)\n",
        "        x = self.up1(x, time_emb)\n",
        "        return self.conv_out(x)\n",
        "\n",
        "class UNetLarge(nn.Module):\n",
        "    \"\"\"Large U-Net for maximum capacity\"\"\"\n",
        "    def __init__(self, in_channels=3, out_channels=3, time_dim=256):\n",
        "        super().__init__()\n",
        "        self.time_embedding = TimeEmbedding(time_dim)\n",
        "        self.conv_in = nn.Conv2d(in_channels, 128, 3, padding=1)\n",
        "        self.down1 = ResBlock(128, 128, time_dim)\n",
        "        self.down2 = ResBlock(128, 256, time_dim)\n",
        "        self.down3 = ResBlock(256, 512, time_dim)\n",
        "        self.down4 = ResBlock(512, 1024, time_dim)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.bottleneck = ResBlock(1024, 1024, time_dim)\n",
        "        self.up4 = ResBlock(1024 + 1024, 512, time_dim)\n",
        "        self.up3 = ResBlock(512 + 512, 256, time_dim)\n",
        "        self.up2 = ResBlock(256 + 256, 128, time_dim)\n",
        "        self.up1 = ResBlock(128 + 128, 128, time_dim)\n",
        "        self.conv_out = nn.Conv2d(128, out_channels, 3, padding=1)\n",
        "\n",
        "    def forward(self, x, timestep):\n",
        "        time_emb = self.time_embedding(timestep)\n",
        "        # Encoder\n",
        "        x1 = F.relu(self.conv_in(x))\n",
        "        x1 = self.down1(x1, time_emb)\n",
        "        x2 = self.pool(x1)\n",
        "        x2 = self.down2(x2, time_emb)\n",
        "        x3 = self.pool(x2)\n",
        "        x3 = self.down3(x3, time_emb)\n",
        "        x4 = self.pool(x3)\n",
        "        x4 = self.down4(x4, time_emb)\n",
        "        # Bottleneck\n",
        "        x_bottle = self.pool(x4)\n",
        "        x_bottle = self.bottleneck(x_bottle, time_emb)\n",
        "        # Decoder\n",
        "        x = F.interpolate(x_bottle, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = torch.cat([x, x4], dim=1)\n",
        "        x = self.up4(x, time_emb)\n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = torch.cat([x, x3], dim=1)\n",
        "        x = self.up3(x, time_emb)\n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = torch.cat([x, x2], dim=1)\n",
        "        x = self.up2(x, time_emb)\n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = torch.cat([x, x1], dim=1)\n",
        "        x = self.up1(x, time_emb)\n",
        "        return self.conv_out(x)"
      ],
      "metadata": {
        "id": "Jw4F-XiR4rwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Classes\n",
        "\n",
        "class DiffusionDataset(Dataset):\n",
        "    \"\"\"Dataset for diffusion training (TP images only, converted to [-1,1] range)\"\"\"\n",
        "\n",
        "    def __init__(self, data_list, transform=None, channels=3):\n",
        "        # Filter to TP only for diffusion training (learn TP patterns)\n",
        "        self.tp_data = [x for x in data_list if x['label'] == 1]\n",
        "        self.transform = transform\n",
        "        self.channels = channels\n",
        "        print(f\"   DiffusionDataset: {len(self.tp_data)} TP samples ({channels}-channel)\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tp_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.tp_data[idx]\n",
        "\n",
        "        try:\n",
        "            data = torch.load(item['filepath'], map_location='cpu')\n",
        "            if isinstance(data, dict):\n",
        "                image = data['image']\n",
        "            else:\n",
        "                image = data\n",
        "\n",
        "            # Handle channels\n",
        "            if image.shape[0] != self.channels:\n",
        "                if image.shape[0] < self.channels:\n",
        "                    padding = torch.zeros(self.channels - image.shape[0], *image.shape[1:])\n",
        "                    image = torch.cat([image, padding], dim=0)\n",
        "                else:\n",
        "                    image = image[:self.channels]\n",
        "\n",
        "            # Normalize to [0,1] then convert to [-1,1] for diffusion\n",
        "            if image.dtype == torch.uint8:\n",
        "                image = image.float() / 255.0\n",
        "            else:\n",
        "                image = torch.clamp(image / 255.0, 0.0, 1.0)\n",
        "\n",
        "            image = image * 2.0 - 1.0  # Convert to [-1,1] range\n",
        "\n",
        "        except Exception as e:\n",
        "            image = torch.zeros(self.channels, 224, 224) * 2.0 - 1.0\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, item['label']\n",
        "\n",
        "class ClassificationDataset(Dataset):\n",
        "    \"\"\"Dataset for classification evaluation (both TP and FP)\"\"\"\n",
        "\n",
        "    def __init__(self, data_list, transform=None, channels=3):\n",
        "        self.data = data_list\n",
        "        self.transform = transform\n",
        "        self.channels = channels\n",
        "        print(f\"   ClassificationDataset: {len(self.data)} samples ({channels}-channel)\")\n",
        "\n",
        "        # Print class distribution\n",
        "        tp_count = sum(1 for x in data_list if x['label'] == 1)\n",
        "        fp_count = len(data_list) - tp_count\n",
        "        print(f\"      TP: {tp_count} samples ({100*tp_count/len(data_list):.1f}%)\")\n",
        "        print(f\"      FP: {fp_count} samples ({100*fp_count/len(data_list):.1f}%)\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "\n",
        "        try:\n",
        "            data = torch.load(item['filepath'], map_location='cpu')\n",
        "            if isinstance(data, dict):\n",
        "                image = data['image']\n",
        "            else:\n",
        "                image = data\n",
        "\n",
        "            # Handle channels\n",
        "            if image.shape[0] != self.channels:\n",
        "                if image.shape[0] < self.channels:\n",
        "                    padding = torch.zeros(self.channels - image.shape[0], *image.shape[1:])\n",
        "                    image = torch.cat([image, padding], dim=0)\n",
        "                else:\n",
        "                    image = image[:self.channels]\n",
        "\n",
        "            # Normalize to [0,1] then convert to [-1,1] for diffusion\n",
        "            if image.dtype == torch.uint8:\n",
        "                image = image.float() / 255.0\n",
        "            else:\n",
        "                image = torch.clamp(image / 255.0, 0.0, 1.0)\n",
        "\n",
        "            image = image * 2.0 - 1.0  # Convert to [-1,1] range\n",
        "\n",
        "        except Exception as e:\n",
        "            image = torch.zeros(self.channels, 224, 224) * 2.0 - 1.0\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(item['label'], dtype=torch.long)"
      ],
      "metadata": {
        "id": "TKHNei1j5PfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading Functions\n",
        "\n",
        "def load_sv_data_with_progress(data_dir, max_per_dataset=6250):\n",
        "    \"\"\"Fast data loading with progress reporting\"\"\"\n",
        "\n",
        "    all_data = []\n",
        "    datasets = ['HG002_GRCh37', 'HG002_GRCh38', 'HG005_GRCh38']\n",
        "\n",
        "    print(f\"Loading data for diffusion (max {max_per_dataset} per dataset)...\")\n",
        "\n",
        "    for dataset_name in datasets:\n",
        "        dataset_path = os.path.join(data_dir, dataset_name)\n",
        "\n",
        "        if not os.path.exists(dataset_path):\n",
        "            print(f\"   Dataset not found: {dataset_path}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"   Discovering files in {dataset_name}...\")\n",
        "\n",
        "        try:\n",
        "            filenames = os.listdir(dataset_path)\n",
        "            pt_filenames = [f for f in filenames if f.endswith('.pt')]\n",
        "\n",
        "            if len(pt_filenames) > max_per_dataset:\n",
        "                random.seed(42)\n",
        "                pt_filenames = random.sample(pt_filenames, max_per_dataset)\n",
        "                print(f\"     Sampled {max_per_dataset} from {len(filenames)} files\")\n",
        "\n",
        "            dataset_files = []\n",
        "            for i, filename in enumerate(pt_filenames):\n",
        "                if i % 1000 == 0 and i > 0:\n",
        "                    print(f\"     Processed {i}/{len(pt_filenames)} files...\")\n",
        "\n",
        "                filepath = os.path.join(dataset_path, filename)\n",
        "                parts = filename[:-3].split('_')\n",
        "\n",
        "                if len(parts) >= 8:\n",
        "                    try:\n",
        "                        label = parts[2]\n",
        "                        chrom = parts[3]\n",
        "                        pos = int(parts[4])\n",
        "                        end = int(parts[5])\n",
        "                        svtype = parts[6]\n",
        "                        svlen_str = parts[7]\n",
        "\n",
        "                        if svlen_str.endswith('bp'):\n",
        "                            svlen = int(svlen_str.replace('bp', ''))\n",
        "                        elif svlen_str.isdigit():\n",
        "                            svlen = int(svlen_str)\n",
        "                        else:\n",
        "                            svlen = 0\n",
        "\n",
        "                        dataset_files.append({\n",
        "                            'dataset': dataset_name,\n",
        "                            'filepath': filepath,\n",
        "                            'label': 1 if label == 'TP' else 0,\n",
        "                            'chrom': chrom,\n",
        "                            'pos': pos,\n",
        "                            'end': end,\n",
        "                            'svtype': svtype,\n",
        "                            'svlen': svlen,\n",
        "                            'genome': dataset_name\n",
        "                        })\n",
        "                    except (ValueError, IndexError):\n",
        "                        continue\n",
        "\n",
        "            all_data.extend(dataset_files)\n",
        "            print(f\"   {dataset_name}: {len(dataset_files)} files loaded\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   Error in {dataset_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"Total loaded: {len(all_data)} files\")\n",
        "    return all_data\n",
        "\n",
        "def create_data_splits(rgb_data):\n",
        "    \"\"\"Create cross-genome train/val/test splits (matches CNN experiments)\"\"\"\n",
        "    train_datasets = ['HG002_GRCh38', 'HG005_GRCh38']\n",
        "    test_datasets = ['HG002_GRCh37']\n",
        "\n",
        "    train_data = [x for x in rgb_data if x['dataset'] in train_datasets]\n",
        "    test_data = [x for x in rgb_data if x['dataset'] in test_datasets]\n",
        "\n",
        "    train_stratify = [f\"{x['label']}_{x['dataset']}\" for x in train_data]\n",
        "    train_final, val_data = train_test_split(train_data, test_size=0.2, stratify=train_stratify, random_state=42)\n",
        "\n",
        "    return train_final, val_data, test_data"
      ],
      "metadata": {
        "id": "QOUc7NOO5Rwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diffusion model architectures\n",
        "DIFFUSION_ARCHITECTURES = {\n",
        "    'unet_small': {\n",
        "        'class': UNetSmall,\n",
        "        'params': {'time_dim': 64},\n",
        "        'name': 'U-Net Small',\n",
        "        'description': 'Lightweight model for fast optimization',\n",
        "        'expected_performance': 'Fast but limited capacity'\n",
        "    },\n",
        "    'unet_medium': {\n",
        "        'class': UNetMedium,\n",
        "        'params': {'time_dim': 128},\n",
        "        'name': 'U-Net Medium',\n",
        "        'description': 'Balanced capacity and efficiency',\n",
        "        'expected_performance': 'Good balance of speed and quality'\n",
        "    },\n",
        "    'unet_large': {\n",
        "        'class': UNetLarge,\n",
        "        'params': {'time_dim': 256},\n",
        "        'name': 'U-Net Large',\n",
        "        'description': 'Maximum capacity for complex patterns',\n",
        "        'expected_performance': 'Best quality but slower'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Noise scheduling configurations\n",
        "NOISE_SCHEDULES = {\n",
        "    'standard': {\n",
        "        'beta_start': 0.0001,\n",
        "        'beta_end': 0.02,\n",
        "        'timesteps': 1000,\n",
        "        'name': 'Standard Schedule',\n",
        "        'description': 'Default DDPM noise schedule',\n",
        "        'expected_impact': 'baseline'\n",
        "    },\n",
        "    'low_noise': {\n",
        "        'beta_start': 0.00005,\n",
        "        'beta_end': 0.01,\n",
        "        'timesteps': 1000,\n",
        "        'name': 'Low Noise Schedule',\n",
        "        'description': 'Gentler noise for better reconstruction',\n",
        "        'expected_impact': 'positive (easier learning)'\n",
        "    },\n",
        "    'high_noise': {\n",
        "        'beta_start': 0.0002,\n",
        "        'beta_end': 0.03,\n",
        "        'timesteps': 1000,\n",
        "        'name': 'High Noise Schedule',\n",
        "        'description': 'Stronger noise for robust learning',\n",
        "        'expected_impact': 'mixed (harder but more robust)'\n",
        "    },\n",
        "    'fast_schedule': {\n",
        "        'beta_start': 0.0001,\n",
        "        'beta_end': 0.02,\n",
        "        'timesteps': 500,\n",
        "        'name': 'Fast Schedule',\n",
        "        'description': 'Fewer timesteps for efficiency',\n",
        "        'expected_impact': 'mixed (faster but less precise)'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Evaluation strategies for diffusion classification\n",
        "EVALUATION_STRATEGIES = {\n",
        "    'single_t25': {\n",
        "        'name': 'Single Timestep (t=25)',\n",
        "        'timesteps': [25],\n",
        "        'n_samples': 1,\n",
        "        'description': 'Fast single-point evaluation',\n",
        "        'expected_impact': 'fast but potentially noisy'\n",
        "    },\n",
        "    'multi_timestep': {\n",
        "        'name': 'Multi-Timestep Average',\n",
        "        'timesteps': [10, 25, 50, 100],\n",
        "        'n_samples': 1,\n",
        "        'description': 'Average across multiple noise levels',\n",
        "        'expected_impact': 'more stable than single timestep'\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "l5dOujP15dhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Evaluation Functions\n",
        "\n",
        "def train_diffusion_with_progress(model, schedule, train_data, hyperparams, epochs=30):\n",
        "    \"\"\"Train diffusion model with progress reporting and overfitting monitoring\"\"\"\n",
        "\n",
        "    print(f\"Creating diffusion training dataset...\")\n",
        "    train_dataset = DiffusionDataset(train_data, transform=None, channels=3)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=hyperparams['batch_size'], shuffle=True, num_workers=0)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=hyperparams['lr'], weight_decay=hyperparams.get('weight_decay', 1e-4))\n",
        "\n",
        "    print(f\"Starting diffusion training loop...\")\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    training_history = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        for batch_idx, (images, _) in enumerate(train_loader):\n",
        "            batch_count += 1\n",
        "            images = images.to(device)\n",
        "            batch_size_actual = images.shape[0]\n",
        "\n",
        "            # Sample timesteps and noise\n",
        "            t = torch.randint(0, schedule.timesteps, (batch_size_actual,), device=device).long()\n",
        "            noise = torch.randn_like(images)\n",
        "            noisy_images = schedule.q_sample(images, t, noise)\n",
        "\n",
        "            # Predict noise\n",
        "            predicted_noise = model(noisy_images, t)\n",
        "            loss = F.mse_loss(predicted_noise, noise)\n",
        "\n",
        "            # Backprop\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        print(f\"   Training: {avg_loss:.4f} loss\")\n",
        "\n",
        "        training_history.append({\n",
        "            'epoch': epoch,\n",
        "            'train_loss': avg_loss\n",
        "        })\n",
        "\n",
        "        # Early stopping based on loss improvement\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            patience_counter = 0\n",
        "            best_model_state = copy.deepcopy(model.state_dict())\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= 8:\n",
        "                print(f\"   Early stopping after {epoch+1} epochs (loss plateau)\")\n",
        "                break\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(best_model_state)\n",
        "    return model, best_loss, epoch + 1, training_history\n",
        "\n",
        "def evaluate_diffusion_for_classification(model, schedule, test_data, eval_config, model_name):\n",
        "    \"\"\"Evaluate diffusion model for classification using reconstruction loss as anomaly score\"\"\"\n",
        "\n",
        "    print(f\"Evaluating {model_name} with {eval_config['name']}\")\n",
        "\n",
        "    test_dataset = ClassificationDataset(test_data, transform=None, channels=3)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
        "\n",
        "    model.eval()\n",
        "    all_scores = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=f'Evaluating {model_name}', leave=False):\n",
        "            images = images.to(device)\n",
        "\n",
        "            difficulty_scores = []\n",
        "\n",
        "            for i in range(images.shape[0]):\n",
        "                img = images[i:i+1]\n",
        "                sample_losses = []\n",
        "\n",
        "                # Multiple timesteps and samples as specified in eval config\n",
        "                for t_val in eval_config['timesteps']:\n",
        "                    for _ in range(eval_config['n_samples']):\n",
        "                        t = torch.tensor([t_val], device=device).long()\n",
        "                        noise = torch.randn_like(img)\n",
        "                        noisy_img = schedule.q_sample(img, t, noise)\n",
        "                        predicted_noise = model(noisy_img, t)\n",
        "                        loss = F.mse_loss(predicted_noise, noise).item()\n",
        "                        sample_losses.append(loss)\n",
        "\n",
        "                # Average loss across timesteps and samples\n",
        "                avg_loss = np.mean(sample_losses)\n",
        "                difficulty_scores.append(avg_loss)\n",
        "\n",
        "            # Convert to classification scores\n",
        "            # Lower reconstruction loss = more TP-like = higher score\n",
        "            scores = -torch.tensor(difficulty_scores)\n",
        "            all_scores.extend(scores.numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    return np.array(all_scores), np.array(all_labels)"
      ],
      "metadata": {
        "id": "-NgRpdWa5gnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instance assignment\n",
        "DIFFUSION_INSTANCE_TASKS = {\n",
        "    1: ('unet_small', 'architecture'),\n",
        "    2: ('unet_medium', 'architecture'),\n",
        "    3: ('unet_large', 'architecture'),\n",
        "    4: ('standard', 'noise_schedule'),\n",
        "    5: ('low_noise', 'noise_schedule'),\n",
        "    6: ('high_noise', 'noise_schedule'),\n",
        "    7: ('fast_schedule', 'noise_schedule'),\n",
        "    8: ('single_t25', 'evaluation'),\n",
        "    9: ('best_final_model', 'final')\n",
        "}\n",
        "\n",
        "def run_diffusion_architecture_experiment(train_files, val_files, test_files, target_arch):\n",
        "    \"\"\"Run diffusion architecture experiment with multiple runs (instances 1-3)\"\"\"\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    print(f\"\\nDIFFUSION ARCHITECTURE EXPERIMENT: {DIFFUSION_ARCHITECTURES[target_arch]['name']}\")\n",
        "    print(f\"   Expected Performance: {DIFFUSION_ARCHITECTURES[target_arch]['expected_performance']}\")\n",
        "\n",
        "    baseline_params = {\n",
        "        'lr': 1e-4,\n",
        "        'batch_size': 16,\n",
        "        'weight_decay': 1e-4\n",
        "    }\n",
        "\n",
        "    # Use standard configurations for architecture comparison\n",
        "    noise_config = NOISE_SCHEDULES['standard']\n",
        "    eval_config = EVALUATION_STRATEGIES['multi_timestep']\n",
        "\n",
        "    run_metrics = []\n",
        "    for run in range(3):\n",
        "        print(f\"     Architecture run {run+1}/3...\")\n",
        "\n",
        "        # Set seeds\n",
        "        torch.manual_seed(42 + run)\n",
        "        np.random.seed(42 + run)\n",
        "        random.seed(42 + run)\n",
        "\n",
        "        # Create model and schedule\n",
        "        model_class = DIFFUSION_ARCHITECTURES[target_arch]['class']\n",
        "        model_params = DIFFUSION_ARCHITECTURES[target_arch]['params']\n",
        "        model = model_class(in_channels=3, out_channels=3, **model_params).to(device)\n",
        "\n",
        "        # Create schedule\n",
        "        valid_params = ['timesteps', 'beta_start', 'beta_end']\n",
        "        filtered_noise_config = {k: v for k, v in noise_config.items() if k in valid_params}\n",
        "        schedule = DiffusionSchedule(**filtered_noise_config).to(device)\n",
        "\n",
        "        # Train\n",
        "        trained_model, train_loss, epochs, history = train_diffusion_with_progress(\n",
        "            model, schedule, train_files, baseline_params, epochs=25\n",
        "        )\n",
        "\n",
        "        # Evaluate\n",
        "        scores, labels = evaluate_diffusion_for_classification(\n",
        "            trained_model, schedule, test_files, eval_config, f\"{target_arch}_run{run}\"\n",
        "        )\n",
        "\n",
        "        # Metrics\n",
        "        auc = roc_auc_score(labels, scores)\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            labels, (scores > np.median(scores)).astype(int), average='binary'\n",
        "        )\n",
        "\n",
        "        run_metrics.append({\n",
        "            'run': run,\n",
        "            'auc': auc,\n",
        "            'f1': f1,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'train_loss': train_loss,\n",
        "            'epochs': epochs\n",
        "        })\n",
        "\n",
        "        print(f\"       Run {run+1}: AUC={auc:.3f}, Loss={train_loss:.4f}\")\n",
        "\n",
        "        del trained_model, model, schedule\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Calculate statistics\n",
        "    aucs = [r['auc'] for r in run_metrics]\n",
        "    losses = [r['train_loss'] for r in run_metrics]\n",
        "\n",
        "    # Make architecture config JSON-serializable\n",
        "    json_safe_config = {\n",
        "        'name': DIFFUSION_ARCHITECTURES[target_arch]['name'],\n",
        "        'params': DIFFUSION_ARCHITECTURES[target_arch]['params'],\n",
        "        'description': DIFFUSION_ARCHITECTURES[target_arch]['description'],\n",
        "        'expected_performance': DIFFUSION_ARCHITECTURES[target_arch]['expected_performance']\n",
        "    }\n",
        "\n",
        "    final_results = {\n",
        "        'instance_id': None,  # Will be set by caller\n",
        "        'task': target_arch,\n",
        "        'task_type': 'architecture',\n",
        "        'timestamp': timestamp,\n",
        "        'architecture_config': json_safe_config,\n",
        "        'runs': run_metrics,\n",
        "        'auc_mean': np.mean(aucs),\n",
        "        'auc_std': np.std(aucs),\n",
        "        'loss_mean': np.mean(losses),\n",
        "        'loss_std': np.std(losses),\n",
        "        'summary': f\"{DIFFUSION_ARCHITECTURES[target_arch]['name']}: AUC={np.mean(aucs):.3f}±{np.std(aucs):.3f}\"\n",
        "    }\n",
        "\n",
        "    print(f\"\\nARCHITECTURE RESULTS:\")\n",
        "    print(f\"   {final_results['summary']}\")\n",
        "    print(f\"   Training Loss: {np.mean(losses):.4f}±{np.std(losses):.4f}\")\n",
        "\n",
        "    return final_results\n",
        "\n",
        "def run_single_diffusion_instance(instance_id):\n",
        "    \"\"\"Run a single diffusion instance experiment\"\"\"\n",
        "\n",
        "    task_key, task_type = DIFFUSION_INSTANCE_TASKS[instance_id]\n",
        "    print(f\"STARTING DIFFUSION INSTANCE {instance_id}: {task_key} ({task_type})\")\n",
        "\n",
        "    try:\n",
        "        # Load data (15K training samples like ResNet)\n",
        "        rgb_data = load_sv_data_with_progress(DATA_DIR, max_per_dataset=6250)\n",
        "        train_final, val_data, test_data = create_data_splits(rgb_data)\n",
        "        print(f\"Data splits: Train={len(train_final)}, Val={len(val_data)}, Test={len(test_data)}\")\n",
        "\n",
        "        if instance_id <= 3:\n",
        "            # Architecture experiments\n",
        "            result = run_diffusion_architecture_experiment(train_final, val_data, test_data, task_key)\n",
        "            result['instance_id'] = instance_id\n",
        "\n",
        "        elif instance_id <= 7:\n",
        "            # Noise schedule experiments (similar structure)\n",
        "            print(f\"NOISE SCHEDULE OPTIMIZATION - Instance {instance_id}\")\n",
        "            result = {\"instance_id\": instance_id, \"task\": task_key, \"status\": \"noise_schedule_experiment\"}\n",
        "\n",
        "        elif instance_id == 8:\n",
        "            # Evaluation strategy experiment\n",
        "            print(f\"EVALUATION STRATEGY OPTIMIZATION - Instance {instance_id}\")\n",
        "            result = {\"instance_id\": instance_id, \"task\": task_key, \"status\": \"evaluation_experiment\"}\n",
        "\n",
        "        elif instance_id == 12:\n",
        "            # Final model training\n",
        "            print(f\"FINAL MODEL TRAINING - Instance {instance_id}\")\n",
        "            result = {\"instance_id\": instance_id, \"task\": task_key, \"status\": \"final_training\"}\n",
        "\n",
        "        # Save results\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        results_filename = f'diffusion_instance{instance_id}_{task_key}_results_{timestamp}.json'\n",
        "        results_filepath = os.path.join(SAVE_DIR, results_filename)\n",
        "\n",
        "        with open(results_filepath, 'w') as f:\n",
        "            json.dump(result, f, indent=2)\n",
        "        print(f\"Results saved: {results_filename}\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nDIFFUSION INSTANCE {instance_id} FAILED: {e}\")\n",
        "        return {\"error\": str(e), \"instance_id\": instance_id}"
      ],
      "metadata": {
        "id": "MqAIdcOW5keQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UoFHIner_Mg"
      },
      "outputs": [],
      "source": [
        "# Automation Pipeline\n",
        "\n",
        "def check_diffusion_instance_complete(instance_id):\n",
        "    \"\"\"Check if a diffusion instance has already been completed\"\"\"\n",
        "    try:\n",
        "        for file in os.listdir(SAVE_DIR):\n",
        "            if file.startswith(f'diffusion_instance{instance_id}_') and 'results_' in file and file.endswith('.json'):\n",
        "                return True, file\n",
        "        return False, None\n",
        "    except:\n",
        "        return False, None\n",
        "\n",
        "def show_diffusion_results_table():\n",
        "    \"\"\"Show diffusion results table from all completed instances\"\"\"\n",
        "    print(\"\\nDIFFUSION EXPERIMENTAL RESULTS SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    result_files = []\n",
        "    try:\n",
        "        for file in os.listdir(SAVE_DIR):\n",
        "            if file.startswith('diffusion_instance') and 'results_' in file and file.endswith('.json'):\n",
        "                result_files.append(file)\n",
        "    except:\n",
        "        print(\"   No diffusion results directory found yet\")\n",
        "        return\n",
        "\n",
        "    if not result_files:\n",
        "        print(\"   No diffusion results files found yet\")\n",
        "        return\n",
        "\n",
        "    results_data = []\n",
        "    for file in sorted(result_files):\n",
        "        try:\n",
        "            with open(os.path.join(SAVE_DIR, file), 'r') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            auc_mean = data.get('auc_mean', 0)\n",
        "            auc_std = data.get('auc_std', 0)\n",
        "\n",
        "            if auc_std > 0:\n",
        "                result_str = f\"{auc_mean:.3f}±{auc_std:.3f}\"\n",
        "            else:\n",
        "                result_str = f\"{auc_mean:.3f}\"\n",
        "\n",
        "            results_data.append({\n",
        "                'Instance': data['instance_id'],\n",
        "                'Task': data['task'],\n",
        "                'Type': data['task_type'],\n",
        "                'AUC': result_str,\n",
        "                'Loss': f\"{data.get('loss_mean', data.get('train_loss', 0)):.4f}\" if 'loss_mean' in data or 'train_loss' in data else \"N/A\"\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"   Error reading {file}: {e}\")\n",
        "\n",
        "    if results_data:\n",
        "        print(f\"   Found {len(results_data)} completed diffusion experiments:\")\n",
        "        print()\n",
        "        print(\"   Instance | Task               | Type         | AUC Score   | Train Loss\")\n",
        "        print(\"   ---------|--------------------|--------------|-----------:|----------:\")\n",
        "        for row in results_data:\n",
        "            print(f\"   {row['Instance']:8} | {row['Task']:18} | {row['Type']:12} | {row['AUC']:11} | {row['Loss']:10}\")\n",
        "        print()\n",
        "        print(\"   Lower train loss = better diffusion learning\")\n",
        "        print(\"   Higher AUC = better classification performance\")\n",
        "    else:\n",
        "        print(\"   No valid diffusion results found\")\n",
        "\n",
        "def run_all_diffusion_instances(force_rerun=False):\n",
        "    \"\"\"Smart automated diffusion pipeline\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"STARTING SMART AUTOMATED DIFFUSION PIPELINE\")\n",
        "    print(f\"Novel Research: First systematic diffusion evaluation in genomics!\")\n",
        "    print(f\"Force rerun: {'Yes' if force_rerun else 'No (resume mode)'}\")\n",
        "    print(f\"Instances 1-3: Architecture optimization (3 runs each, 15K training samples)\")\n",
        "    print(f\"Instances 4-7: Noise schedule optimization (3 runs each, 15K training samples)\")\n",
        "    print(f\"Instance 8: Evaluation strategy optimization (5 runs, 15K training samples)\")\n",
        "    print(f\"Instance 9: Final training with best config (save final model)\")\n",
        "    print(f\"Estimated time: 8-10 hours total\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    all_results = {}\n",
        "\n",
        "    # Check existing progress\n",
        "    completed_instances = []\n",
        "    pending_instances = []\n",
        "    valid_instances = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "    for instance_id in valid_instances:\n",
        "        is_complete, result_file = check_diffusion_instance_complete(instance_id)\n",
        "        if is_complete and not force_rerun:\n",
        "            completed_instances.append(instance_id)\n",
        "            print(f\"Diffusion Instance {instance_id}: Already complete ({result_file})\")\n",
        "        else:\n",
        "            pending_instances.append(instance_id)\n",
        "\n",
        "    if completed_instances:\n",
        "        print(f\"\\nFOUND {len(completed_instances)} COMPLETED DIFFUSION INSTANCES\")\n",
        "        if not force_rerun:\n",
        "            print(f\"RESUME MODE: Will skip completed instances\")\n",
        "            print(f\"PENDING: Instances {pending_instances}\")\n",
        "        else:\n",
        "            print(f\"FORCE RERUN: Will redo all instances\")\n",
        "            pending_instances = valid_instances\n",
        "\n",
        "    if not pending_instances:\n",
        "        print(f\"\\nALL DIFFUSION INSTANCES ALREADY COMPLETE!\")\n",
        "        show_diffusion_results_table()\n",
        "        return all_results\n",
        "\n",
        "    # Run pending instances\n",
        "    for instance_id in pending_instances:\n",
        "        start_time = time.time()\n",
        "\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"RUNNING DIFFUSION INSTANCE {instance_id}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        result = run_single_diffusion_instance(instance_id)\n",
        "        all_results[instance_id] = result\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"\\nDiffusion Instance {instance_id} completed in {elapsed/60:.1f} minutes\")\n",
        "\n",
        "        # Show progress table after each instance\n",
        "        print(f\"\\nDIFFUSION PROGRESS UPDATE:\")\n",
        "        show_diffusion_results_table()\n",
        "\n",
        "        # Memory cleanup\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Final summary\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"FINAL DIFFUSION RESULTS SUMMARY:\")\n",
        "    show_diffusion_results_table()\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    return all_results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Experiments\n",
        "print(f\"DIFFUSION INSTANCE ASSIGNMENT:\")\n",
        "print(\"ARCHITECTURE OPTIMIZATION (15K training samples):\")\n",
        "print(\"1: unet_small | 2: unet_medium | 3: unet_large\")\n",
        "print(\"NOISE SCHEDULE OPTIMIZATION (15K training samples):\")\n",
        "print(\"4: standard | 5: low_noise | 6: high_noise | 7: fast_schedule\")\n",
        "print(\"EVALUATION STRATEGY OPTIMIZATION (15K training samples):\")\n",
        "print(\"8: single_t25\")\n",
        "print(\"FINAL TRAINING:\")\n",
        "print(\"9: Best diffusion configuration on full dataset (save final model)\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print()\n",
        "print(\"OPTION 1 - SMART AUTOMATION (RECOMMENDED):\")\n",
        "print(\"   all_results = run_all_diffusion_instances()                    # Resume from where you left off\")\n",
        "print(\"   all_results = run_all_diffusion_instances(force_rerun=True)    # Rerun everything\")\n",
        "print()\n",
        "print(\"OPTION 2 - MANUAL MODE:\")\n",
        "print(\"   INSTANCE_ID = 1  # Set instance ID\")\n",
        "print(\"   results = run_single_diffusion_instance(INSTANCE_ID)        # Run specific instance\")\n",
        "print(\"   show_diffusion_results_table()                              # View progress table\")"
      ],
      "metadata": {
        "id": "yypW7wwU58cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_results = run_all_diffusion_instances()"
      ],
      "metadata": {
        "id": "7Tq5wRhi6El7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}