{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Multimodal Ensemble Training\n",
        "\n",
        "Fusion of multiple feature modalities for genomic structural variant classification\n",
        "\n",
        "Models tested:\n",
        "- Attention Fusion: Multi-head attention across Diffusion + Linear features\n",
        "- Diffusion Only: Diffusion features baseline\n",
        "- Linear Only: Linear/scalar features baseline"
      ],
      "metadata": {
        "id": "gqN_X8xzREVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import h5py\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, classification_report\n",
        "import json\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration - GitHub repository structure\n",
        "DATA_DIR = '../data/processed'\n",
        "SAVE_DIR = '../data/processed/multimodal_experiments'\n",
        "MODELS_DIR = '../data/processed/multimodal_experiments/models'\n",
        "FIGURES_DIR = '../figures'\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
        "\n",
        "print(f\"Save directory: {SAVE_DIR}\")"
      ],
      "metadata": {
        "id": "6y1yfygKRLXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading and alignment\n",
        "\n",
        "def load_all_modalities():\n",
        "    \"\"\"Load all feature modalities\"\"\"\n",
        "\n",
        "    print(\"Loading all feature modalities...\")\n",
        "\n",
        "    modalities = {}\n",
        "\n",
        "    # Load ResNet features\n",
        "    resnet_features_path = os.path.join(DATA_DIR, 'resnet_latents/resnet50_features.h5')\n",
        "    resnet_metadata_path = os.path.join(DATA_DIR, 'resnet_latents/resnet50_metadata.csv')\n",
        "\n",
        "    if os.path.exists(resnet_features_path) and os.path.exists(resnet_metadata_path):\n",
        "        with h5py.File(resnet_features_path, 'r') as f:\n",
        "            modalities['resnet_features'] = f['features'][:]\n",
        "        modalities['resnet_metadata'] = pd.read_csv(resnet_metadata_path)\n",
        "        print(f\"   ResNet: {modalities['resnet_features'].shape}\")\n",
        "\n",
        "    # Load VICReg features\n",
        "    vicreg_features_path = os.path.join(DATA_DIR, 'vicreg_latents/vicreg_features.h5')\n",
        "    vicreg_metadata_path = os.path.join(DATA_DIR, 'vicreg_latents/vicreg_metadata.csv')\n",
        "\n",
        "    if os.path.exists(vicreg_features_path) and os.path.exists(vicreg_metadata_path):\n",
        "        with h5py.File(vicreg_features_path, 'r') as f:\n",
        "            modalities['vicreg_features'] = f['features'][:]\n",
        "        modalities['vicreg_metadata'] = pd.read_csv(vicreg_metadata_path)\n",
        "        print(f\"   VICReg: {modalities['vicreg_features'].shape}\")\n",
        "\n",
        "    # Load Diffusion features\n",
        "    diffusion_features_path = os.path.join(DATA_DIR, 'diffusion_latents/diffusion_raw_latents_features.h5')\n",
        "    diffusion_metadata_path = os.path.join(DATA_DIR, 'diffusion_latents/diffusion_raw_latents_metadata.csv')\n",
        "\n",
        "    if os.path.exists(diffusion_features_path) and os.path.exists(diffusion_metadata_path):\n",
        "        with h5py.File(diffusion_features_path, 'r') as f:\n",
        "            modalities['diffusion_features'] = f['features'][:]\n",
        "        modalities['diffusion_metadata'] = pd.read_csv(diffusion_metadata_path)\n",
        "        print(f\"   Diffusion: {modalities['diffusion_features'].shape}\")\n",
        "\n",
        "    # Load SAE features\n",
        "    sae_features_path = os.path.join(DATA_DIR, 'sae_latents/sae_latents_combined.pt')\n",
        "\n",
        "    if os.path.exists(sae_features_path):\n",
        "        sae_data = torch.load(sae_features_path, map_location='cpu', weights_only=False)\n",
        "        modalities['sae_data'] = sae_data\n",
        "        print(f\"   SAE: {sae_data['dense_features'].shape}\")\n",
        "\n",
        "    # Load scalar features\n",
        "    scalar_features_path = os.path.join(DATA_DIR, 'SV_Features_CLEANED_Dataset.csv')\n",
        "\n",
        "    if os.path.exists(scalar_features_path):\n",
        "        modalities['scalar_df'] = pd.read_csv(scalar_features_path)\n",
        "        print(f\"   Scalar: {modalities['scalar_df'].shape}\")\n",
        "\n",
        "    return modalities\n",
        "\n",
        "def build_coordinate_aligned_dataset(modalities):\n",
        "    \"\"\"Build precisely aligned multimodal dataset using SAE-ResNet coordinate matching\"\"\"\n",
        "\n",
        "    print(\"Building coordinate-aligned dataset...\")\n",
        "\n",
        "    # Extract SAE data\n",
        "    sae_data = modalities['sae_data']\n",
        "    sae_variants = sae_data['sv_info']\n",
        "    sae_features = sae_data['dense_features']\n",
        "    sae_labels = sae_data['labels']\n",
        "\n",
        "    # Use ResNet metadata for GRCh38 subset\n",
        "    resnet_metadata = modalities['resnet_metadata']\n",
        "    grch38_mask = resnet_metadata['dataset'].str.contains('GRCh38', na=False)\n",
        "    grch38_resnet_metadata = resnet_metadata[grch38_mask].copy().reset_index(drop=True)\n",
        "\n",
        "    # Build ResNet lookup with correct filename parsing\n",
        "    resnet_lookup = {}\n",
        "    for idx, row in grch38_resnet_metadata.iterrows():\n",
        "        filename = row['filename']\n",
        "        parts = filename.split('_')\n",
        "        if len(parts) >= 8:\n",
        "            dataset = f\"{parts[0]}_{parts[1]}\"  # HG002_GRCh38\n",
        "            label = parts[2]  # TP or FP\n",
        "            chrom = parts[3]  # chr1\n",
        "            pos = int(parts[4])  # position\n",
        "            svtype = parts[6]  # INS/DEL/etc\n",
        "            end = int(parts[5])  # end position\n",
        "\n",
        "            key = (dataset, label, chrom, pos, svtype)\n",
        "            resnet_lookup[key] = {\n",
        "                'resnet_idx': idx,\n",
        "                'filename': filename,\n",
        "                'end': end,\n",
        "                'row': row\n",
        "            }\n",
        "\n",
        "    # Find exact coordinate matches\n",
        "    matched_pairs = []\n",
        "    for sae_idx, sae_variant in enumerate(sae_variants):\n",
        "        # Skip non-GRCh38 SAE variants\n",
        "        if not sae_variant['dataset'].endswith('GRCh38'):\n",
        "            continue\n",
        "\n",
        "        # Extract SAE variant info\n",
        "        sae_dataset = sae_variant['dataset']\n",
        "        sae_chrom = sae_variant['chrom']\n",
        "        sae_pos = sae_variant['pos']\n",
        "        sae_end = sae_variant['end']\n",
        "        sae_svtype = sae_variant['svtype']\n",
        "        sae_label = 'TP' if sae_variant.get('truvari_class') == 'tp_comp_vcf' else 'FP'\n",
        "\n",
        "        # Look for ResNet match\n",
        "        key = (sae_dataset, sae_label, sae_chrom, sae_pos, sae_svtype)\n",
        "\n",
        "        if key in resnet_lookup:\n",
        "            candidate = resnet_lookup[key]\n",
        "            # Check coordinate tolerance (Â±1 bp for end position)\n",
        "            if abs(candidate['end'] - sae_end) <= 1:\n",
        "                matched_pairs.append({\n",
        "                    'sae_idx': sae_idx,\n",
        "                    'resnet_idx': candidate['resnet_idx'],\n",
        "                    'sae_variant': sae_variant,\n",
        "                    'resnet_row': candidate['row']\n",
        "                })\n",
        "\n",
        "    n_matches = len(matched_pairs)\n",
        "    print(f\"   Found {n_matches:,} precise coordinate matches\")\n",
        "\n",
        "    if n_matches < 10000:\n",
        "        print(f\"   Warning: Low match count. Expected ~40k matches.\")\n",
        "        return None\n",
        "\n",
        "    # Extract matched indices\n",
        "    sae_matched_indices = [pair['sae_idx'] for pair in matched_pairs]\n",
        "    resnet_matched_indices = [pair['resnet_idx'] for pair in matched_pairs]\n",
        "\n",
        "    # Build aligned feature dictionary\n",
        "    aligned_features = {}\n",
        "\n",
        "    # SAE features\n",
        "    aligned_features['sae'] = sae_features[sae_matched_indices]\n",
        "\n",
        "    # ResNet features\n",
        "    grch38_global_indices = grch38_resnet_metadata.index[resnet_matched_indices].values\n",
        "    aligned_features['resnet'] = modalities['resnet_features'][grch38_global_indices]\n",
        "\n",
        "    # VICReg features (if available)\n",
        "    if 'vicreg_features' in modalities:\n",
        "        aligned_features['vicreg'] = modalities['vicreg_features'][grch38_global_indices]\n",
        "\n",
        "    # Diffusion features (if available)\n",
        "    if 'diffusion_features' in modalities:\n",
        "        aligned_features['diffusion'] = modalities['diffusion_features'][grch38_global_indices]\n",
        "\n",
        "    # Linear/Scalar features (coordinate-based matching)\n",
        "    if 'scalar_df' in modalities:\n",
        "        scalar_df = modalities['scalar_df']\n",
        "        aligned_scalar_features = []\n",
        "\n",
        "        for pair in matched_pairs:\n",
        "            sae_variant = pair['sae_variant']\n",
        "            # Find scalar match by coordinate\n",
        "            scalar_matches = scalar_df[\n",
        "                (scalar_df['dataset'] == sae_variant['dataset']) &\n",
        "                (scalar_df['chrom'] == sae_variant['chrom']) &\n",
        "                (abs(scalar_df['pos'] - sae_variant['pos']) <= 1)\n",
        "            ]\n",
        "\n",
        "            if len(scalar_matches) > 0:\n",
        "                # Extract numeric features\n",
        "                numeric_cols = scalar_matches.select_dtypes(include=[np.number]).columns\n",
        "                feature_cols = [col for col in numeric_cols if not any(id_word in col.lower()\n",
        "                               for id_word in ['pos', 'end', 'chrom'])]\n",
        "                scalar_row = scalar_matches[feature_cols].iloc[0].fillna(0).values\n",
        "            else:\n",
        "                # Fallback - use zeros\n",
        "                scalar_row = np.zeros(16)  # Standard size including raw svlen\n",
        "\n",
        "            aligned_scalar_features.append(scalar_row)\n",
        "\n",
        "        aligned_features['linear'] = np.array(aligned_scalar_features, dtype=np.float32)\n",
        "\n",
        "    # Extract aligned labels\n",
        "    aligned_labels = sae_labels[sae_matched_indices]\n",
        "\n",
        "    print(f\"Alignment complete:\")\n",
        "    print(f\"   Aligned samples: {len(aligned_labels):,}\")\n",
        "    print(f\"   TP: {np.sum(aligned_labels):,} ({np.mean(aligned_labels)*100:.1f}%)\")\n",
        "    print(f\"   FP: {len(aligned_labels) - np.sum(aligned_labels):,} ({(1-np.mean(aligned_labels))*100:.1f}%)\")\n",
        "    print(f\"   Feature dimensions:\")\n",
        "    for name, features in aligned_features.items():\n",
        "        print(f\"      {name}: {features.shape}\")\n",
        "\n",
        "    return {\n",
        "        'features': aligned_features,\n",
        "        'labels': aligned_labels,\n",
        "        'matched_pairs': matched_pairs,\n",
        "        'n_matches': n_matches\n",
        "    }\n",
        "\n",
        "def fix_linear_features(aligned_data):\n",
        "    \"\"\"Fix linear features by removing raw svlen (first column)\"\"\"\n",
        "\n",
        "    print(\"Fixing linear features: removing raw svlen...\")\n",
        "    print(f\"   Before: {aligned_data['features']['linear'].shape}\")\n",
        "\n",
        "    # Remove first column (raw svlen)\n",
        "    aligned_data['features']['linear'] = aligned_data['features']['linear'][:, 1:]\n",
        "\n",
        "    print(f\"   After: {aligned_data['features']['linear'].shape}\")\n",
        "    print(\"   Now have 15 clean linear features (removed raw svlen)\")\n",
        "\n",
        "    return aligned_data"
      ],
      "metadata": {
        "id": "H9z2ms0cRcON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model architectures\n",
        "\n",
        "class AttentionFusion(nn.Module):\n",
        "    \"\"\"Multi-head attention-based fusion for Diffusion + Linear\"\"\"\n",
        "\n",
        "    def __init__(self, diffusion_dim=2816, linear_dim=15, hidden_dim=256, num_heads=8, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # Modality encoders\n",
        "        self.diffusion_encoder = nn.Sequential(\n",
        "            nn.Linear(diffusion_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        self.linear_encoder = nn.Sequential(\n",
        "            nn.Linear(linear_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        # Multi-head attention\n",
        "        self.attention = nn.MultiheadAttention(\n",
        "            embed_dim=hidden_dim,\n",
        "            num_heads=num_heads,\n",
        "            dropout=0.3,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, diffusion_features, linear_features):\n",
        "        # Encode modalities\n",
        "        diffusion_encoded = self.diffusion_encoder(diffusion_features)\n",
        "        linear_encoded = self.linear_encoder(linear_features)\n",
        "\n",
        "        # Stack for attention\n",
        "        modality_stack = torch.stack([diffusion_encoded, linear_encoded], dim=1)\n",
        "\n",
        "        # Attention across modalities\n",
        "        attended, attention_weights = self.attention(\n",
        "            modality_stack, modality_stack, modality_stack\n",
        "        )\n",
        "\n",
        "        # Classify\n",
        "        output = self.classifier(attended.reshape(attended.size(0), -1))\n",
        "        return output, attention_weights\n",
        "\n",
        "class DiffusionOnly(nn.Module):\n",
        "    \"\"\"Diffusion features only baseline\"\"\"\n",
        "\n",
        "    def __init__(self, diffusion_dim=2816, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(diffusion_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, diffusion_features, linear_features):\n",
        "        output = self.classifier(diffusion_features)\n",
        "        return output, None\n",
        "\n",
        "class LinearOnly(nn.Module):\n",
        "    \"\"\"Linear features only baseline\"\"\"\n",
        "\n",
        "    def __init__(self, linear_dim=15, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(linear_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, diffusion_features, linear_features):\n",
        "        output = self.classifier(linear_features)\n",
        "        return output, None\n"
      ],
      "metadata": {
        "id": "4OgFxYjwRj5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset and training\n",
        "\n",
        "class MultimodalDataset(Dataset):\n",
        "    def __init__(self, diffusion_features, linear_features, labels):\n",
        "        self.diffusion_features = diffusion_features\n",
        "        self.linear_features = linear_features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            self.diffusion_features[idx],\n",
        "            self.linear_features[idx],\n",
        "            self.labels[idx]\n",
        "        )\n",
        "\n",
        "def train_neural_model(model, train_loader, val_loader, epochs=50):\n",
        "    \"\"\"Train a neural model with early stopping\"\"\"\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='max', patience=5, factor=0.5, verbose=False\n",
        "    )\n",
        "\n",
        "    best_val_acc = 0\n",
        "    best_val_auc = 0\n",
        "    patience = 15\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for diffusion_batch, linear_batch, labels_batch in train_loader:\n",
        "            diffusion_batch = diffusion_batch.to(device)\n",
        "            linear_batch = linear_batch.to(device)\n",
        "            labels_batch = labels_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs, _ = model(diffusion_batch, linear_batch)\n",
        "            loss = criterion(outputs, labels_batch)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        val_probs = []\n",
        "        val_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for diffusion_batch, linear_batch, labels_batch in val_loader:\n",
        "                diffusion_batch = diffusion_batch.to(device)\n",
        "                linear_batch = linear_batch.to(device)\n",
        "                labels_batch = labels_batch.to(device)\n",
        "\n",
        "                outputs, _ = model(diffusion_batch, linear_batch)\n",
        "                _, predicted = outputs.max(1)\n",
        "                val_total += labels_batch.size(0)\n",
        "                val_correct += predicted.eq(labels_batch).sum().item()\n",
        "\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "                val_probs.extend(probs[:, 1].cpu().numpy())\n",
        "                val_targets.extend(labels_batch.cpu().numpy())\n",
        "\n",
        "        val_acc = val_correct / val_total\n",
        "        val_auc = roc_auc_score(val_targets, val_probs)\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        scheduler.step(val_acc)\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        # Early stopping\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_val_auc = val_auc\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience or current_lr < 1e-7:\n",
        "            break\n",
        "\n",
        "    return best_val_acc, best_val_auc\n",
        "\n",
        "def calculate_comprehensive_metrics(y_true, y_pred, y_proba):\n",
        "    \"\"\"Calculate all metrics including precision, recall, F1\"\"\"\n",
        "\n",
        "    metrics = {}\n",
        "\n",
        "    # Basic metrics\n",
        "    metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
        "    metrics['precision'] = precision_score(y_true, y_pred, zero_division=0)\n",
        "    metrics['recall'] = recall_score(y_true, y_pred, zero_division=0)\n",
        "    metrics['f1'] = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    # AUC (requires probabilities)\n",
        "    if y_proba is not None and len(np.unique(y_true)) > 1:\n",
        "        metrics['auc'] = roc_auc_score(y_true, y_proba)\n",
        "    else:\n",
        "        metrics['auc'] = 0.5\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "iKrS9TvkRmip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main experiment function\n",
        "\n",
        "def run_multimodal_experiment(aligned_data):\n",
        "    \"\"\"Run comprehensive multimodal architecture comparison\"\"\"\n",
        "\n",
        "    print(\"Running multimodal experiment...\")\n",
        "\n",
        "    if aligned_data is None:\n",
        "        print(\"No aligned data provided!\")\n",
        "        return None\n",
        "\n",
        "    features_dict = aligned_data['features']\n",
        "    labels = aligned_data['labels']\n",
        "\n",
        "    # Extract Diffusion and Linear features\n",
        "    if 'diffusion' not in features_dict or 'linear' not in features_dict:\n",
        "        print(\"Missing Diffusion or Linear features!\")\n",
        "        return None\n",
        "\n",
        "    diffusion_features = features_dict['diffusion']\n",
        "    linear_features = features_dict['linear']\n",
        "\n",
        "    print(f\"Dataset: {len(labels):,} samples\")\n",
        "    print(f\"Diffusion features: {diffusion_features.shape[1]:,}\")\n",
        "    print(f\"Linear features: {linear_features.shape[1]:,}\")\n",
        "    print(f\"Class distribution: TP={np.sum(labels==1)}, FP={np.sum(labels==0)}\")\n",
        "\n",
        "    # Architecture configurations\n",
        "    architectures = {\n",
        "        'Attention_Fusion': lambda: AttentionFusion(diffusion_features.shape[1], linear_features.shape[1]),\n",
        "        'Diffusion_Only': lambda: DiffusionOnly(diffusion_features.shape[1]),\n",
        "        'Linear_Only': lambda: LinearOnly(linear_features.shape[1])\n",
        "    }\n",
        "\n",
        "    # Cross-validation setup\n",
        "    seeds = [42, 123, 456, 789, 999]\n",
        "    n_splits = 5\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    # Test neural architectures\n",
        "    for arch_name, arch_factory in architectures.items():\n",
        "        print(f\"\\nTesting {arch_name}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        arch_results = []\n",
        "\n",
        "        for seed_idx, seed in enumerate(seeds):\n",
        "            print(f\"   Seed {seed} ({seed_idx+1}/{len(seeds)})...\")\n",
        "\n",
        "            # Set seeds\n",
        "            torch.manual_seed(seed)\n",
        "            np.random.seed(seed)\n",
        "\n",
        "            # Cross-validation\n",
        "            skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "            fold_results = []\n",
        "\n",
        "            for fold, (train_idx, val_idx) in enumerate(skf.split(diffusion_features, labels)):\n",
        "\n",
        "                # Checkpoint path\n",
        "                checkpoint_path = os.path.join(\n",
        "                    MODELS_DIR,\n",
        "                    f\"multimodal_{arch_name}_seed{seed}_fold{fold}.pt\"\n",
        "                )\n",
        "\n",
        "                # Check if already computed\n",
        "                if os.path.exists(checkpoint_path):\n",
        "                    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "                    fold_results.append({\n",
        "                        'accuracy': checkpoint['val_accuracy'],\n",
        "                        'auc': checkpoint['val_auc'],\n",
        "                        'precision': checkpoint.get('precision', 0),\n",
        "                        'recall': checkpoint.get('recall', 0),\n",
        "                        'f1': checkpoint.get('f1', 0)\n",
        "                    })\n",
        "                    continue\n",
        "\n",
        "                # Create model\n",
        "                model = arch_factory().to(device)\n",
        "\n",
        "                # Prepare data\n",
        "                X_diffusion_train, X_diffusion_val = diffusion_features[train_idx], diffusion_features[val_idx]\n",
        "                X_linear_train, X_linear_val = linear_features[train_idx], linear_features[val_idx]\n",
        "                y_train, y_val = labels[train_idx], labels[val_idx]\n",
        "\n",
        "                # Scale features\n",
        "                diffusion_scaler = StandardScaler()\n",
        "                linear_scaler = StandardScaler()\n",
        "\n",
        "                X_diffusion_train_scaled = diffusion_scaler.fit_transform(X_diffusion_train)\n",
        "                X_diffusion_val_scaled = diffusion_scaler.transform(X_diffusion_val)\n",
        "\n",
        "                X_linear_train_scaled = linear_scaler.fit_transform(X_linear_train)\n",
        "                X_linear_val_scaled = linear_scaler.transform(X_linear_val)\n",
        "\n",
        "                # Convert to tensors\n",
        "                X_diffusion_train_tensor = torch.FloatTensor(X_diffusion_train_scaled)\n",
        "                X_diffusion_val_tensor = torch.FloatTensor(X_diffusion_val_scaled)\n",
        "                X_linear_train_tensor = torch.FloatTensor(X_linear_train_scaled)\n",
        "                X_linear_val_tensor = torch.FloatTensor(X_linear_val_scaled)\n",
        "                y_train_tensor = torch.LongTensor(y_train)\n",
        "                y_val_tensor = torch.LongTensor(y_val)\n",
        "\n",
        "                # Create data loaders\n",
        "                train_dataset = MultimodalDataset(X_diffusion_train_tensor, X_linear_train_tensor, y_train_tensor)\n",
        "                val_dataset = MultimodalDataset(X_diffusion_val_tensor, X_linear_val_tensor, y_val_tensor)\n",
        "\n",
        "                train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "                val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "                # Train model\n",
        "                val_acc, val_auc = train_neural_model(model, train_loader, val_loader, epochs=50)\n",
        "\n",
        "                # Calculate additional metrics\n",
        "                model.eval()\n",
        "                all_preds = []\n",
        "                all_probs = []\n",
        "                all_targets = []\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    for diffusion_batch, linear_batch, labels_batch in val_loader:\n",
        "                        diffusion_batch = diffusion_batch.to(device)\n",
        "                        linear_batch = linear_batch.to(device)\n",
        "\n",
        "                        outputs, _ = model(diffusion_batch, linear_batch)\n",
        "                        _, predicted = outputs.max(1)\n",
        "                        probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "                        all_preds.extend(predicted.cpu().numpy())\n",
        "                        all_probs.extend(probs[:, 1].cpu().numpy())\n",
        "                        all_targets.extend(labels_batch.numpy())\n",
        "\n",
        "                # Calculate comprehensive metrics\n",
        "                metrics = calculate_comprehensive_metrics(\n",
        "                    np.array(all_targets),\n",
        "                    np.array(all_preds),\n",
        "                    np.array(all_probs)\n",
        "                )\n",
        "\n",
        "                # Save checkpoint\n",
        "                torch.save({\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'val_accuracy': val_acc,\n",
        "                    'val_auc': val_auc,\n",
        "                    'precision': metrics['precision'],\n",
        "                    'recall': metrics['recall'],\n",
        "                    'f1': metrics['f1'],\n",
        "                    'diffusion_scaler': diffusion_scaler,\n",
        "                    'linear_scaler': linear_scaler,\n",
        "                    'arch_name': arch_name,\n",
        "                    'seed': seed,\n",
        "                    'fold': fold\n",
        "                }, checkpoint_path)\n",
        "\n",
        "                fold_results.append({\n",
        "                    'accuracy': val_acc,\n",
        "                    'auc': val_auc,\n",
        "                    'precision': metrics['precision'],\n",
        "                    'recall': metrics['recall'],\n",
        "                    'f1': metrics['f1']\n",
        "                })\n",
        "\n",
        "            # Average across folds for this seed\n",
        "            seed_metrics = {}\n",
        "            for metric in ['accuracy', 'auc', 'precision', 'recall', 'f1']:\n",
        "                seed_metrics[metric] = np.mean([r[metric] for r in fold_results])\n",
        "\n",
        "            arch_results.append(seed_metrics)\n",
        "\n",
        "            print(f\"      Average: {seed_metrics['accuracy']:.4f} acc, {seed_metrics['f1']:.4f} F1\")\n",
        "\n",
        "        # Compile results for this architecture\n",
        "        final_metrics = {}\n",
        "        for metric in ['accuracy', 'auc', 'precision', 'recall', 'f1']:\n",
        "            values = [r[metric] for r in arch_results]\n",
        "            final_metrics[f'{metric}_mean'] = np.mean(values)\n",
        "            final_metrics[f'{metric}_std'] = np.std(values)\n",
        "\n",
        "        all_results.append({\n",
        "            'Architecture': arch_name,\n",
        "            'Type': 'Neural',\n",
        "            **final_metrics,\n",
        "            'Raw_Results': arch_results\n",
        "        })\n",
        "\n",
        "        print(f\"   Final: {final_metrics['f1_mean']:.4f} Â± {final_metrics['f1_std']:.4f} F1\")\n",
        "\n",
        "    # Save results\n",
        "    results_path = os.path.join(SAVE_DIR, \"multimodal_results.pkl\")\n",
        "    with open(results_path, 'wb') as f:\n",
        "        pickle.dump(all_results, f)\n",
        "\n",
        "    print(f\"\\nMultimodal results saved to {results_path}\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "def analyze_multimodal_results(results):\n",
        "    \"\"\"Analyze and display multimodal results\"\"\"\n",
        "\n",
        "    if not results:\n",
        "        print(\"No results to analyze!\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nMULTIMODAL EXPERIMENT RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Sort by F1 score\n",
        "    results_sorted = sorted(results, key=lambda x: x['f1_mean'], reverse=True)\n",
        "\n",
        "    for i, result in enumerate(results_sorted):\n",
        "        print(f\"\\n{i+1}. {result['Architecture']}\")\n",
        "        print(f\"   F1 Score:    {result['f1_mean']:.4f} Â± {result['f1_std']:.4f}\")\n",
        "        print(f\"   Precision:   {result['precision_mean']:.4f} Â± {result['precision_std']:.4f}\")\n",
        "        print(f\"   Recall:      {result['recall_mean']:.4f} Â± {result['recall_std']:.4f}\")\n",
        "        print(f\"   Accuracy:    {result['accuracy_mean']:.4f} Â± {result['accuracy_std']:.4f}\")\n",
        "        print(f\"   AUC:         {result['auc_mean']:.4f} Â± {result['auc_std']:.4f}\")\n",
        "\n",
        "    # Best model\n",
        "    best_model = results_sorted[0]\n",
        "    print(f\"\\nBEST MODEL: {best_model['Architecture']}\")\n",
        "    print(f\"   F1 Score: {best_model['f1_mean']:.4f} Â± {best_model['f1_std']:.4f}\")\n",
        "\n",
        "    # Determine if fusion helps\n",
        "    attention_fusion = next((r for r in results if r['Architecture'] == 'Attention_Fusion'), None)\n",
        "    diffusion_only = next((r for r in results if r['Architecture'] == 'Diffusion_Only'), None)\n",
        "    linear_only = next((r for r in results if r['Architecture'] == 'Linear_Only'), None)\n",
        "\n",
        "    if attention_fusion and diffusion_only and linear_only:\n",
        "        print(f\"\\nFUSION ANALYSIS:\")\n",
        "        fusion_f1 = attention_fusion['f1_mean']\n",
        "        diffusion_f1 = diffusion_only['f1_mean']\n",
        "        linear_f1 = linear_only['f1_mean']\n",
        "\n",
        "        best_single = max(diffusion_f1, linear_f1)\n",
        "        improvement = fusion_f1 - best_single\n",
        "\n",
        "        print(f\"   Best single modality: {best_single:.4f}\")\n",
        "        print(f\"   Attention Fusion:     {fusion_f1:.4f}\")\n",
        "        print(f\"   Improvement:          {improvement:+.4f}\")\n",
        "\n",
        "        if improvement > 0.01:  # 1% improvement threshold\n",
        "            print(f\"   Multimodal fusion provides meaningful improvement!\")\n",
        "        else:\n",
        "            print(f\"   Single modality performance is competitive\")\n",
        "\n",
        "    return results_sorted"
      ],
      "metadata": {
        "id": "61uUaCCDRrAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01dUr_mdRAW-"
      },
      "outputs": [],
      "source": [
        "print(\"MAIN FUNCTIONS:\")\n",
        "print(\"   modalities = load_all_modalities()\")\n",
        "print(\"   aligned_data = build_coordinate_aligned_dataset(modalities)\")\n",
        "print(\"   aligned_data = fix_linear_features(aligned_data)\")\n",
        "print(\"   results = run_multimodal_experiment(aligned_data)\")\n",
        "print(\"   analyze_multimodal_results(results)\")\n",
        "print()\n",
        "print(\"MODELS TESTED:\")\n",
        "print(\"   Attention Fusion: Multi-head attention across Diffusion + Linear\")\n",
        "print(\"   Diffusion Only: Diffusion features baseline\")\n",
        "print(\"   Linear Only: Linear/scalar features baseline\")\n",
        "print()\n",
        "print(\"OUTPUT:\")\n",
        "print(\"   Cross-validated performance with precision/recall/F1\")\n",
        "print(\"   Saved models for best checkpoints\")\n",
        "print(\"   Analysis of fusion vs single-modality performance\")\n",
        "\n",
        "# To run the complete pipeline:\n",
        "# modalities = load_all_modalities()\n",
        "# aligned_data = build_coordinate_aligned_dataset(modalities)\n",
        "# aligned_data = fix_linear_features(aligned_data)\n",
        "# results = run_multimodal_experiment(aligned_data)\n",
        "# analyze_multimodal_results(results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modalities = load_all_modalities()\n",
        "aligned_data = build_coordinate_aligned_dataset(modalities)\n",
        "aligned_data = fix_linear_features(aligned_data)\n",
        "results = run_multimodal_experiment(aligned_data)\n",
        "analyze_multimodal_results(results)"
      ],
      "metadata": {
        "id": "vufPkWpmRu7k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}