{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of SAE atoms that specialize in detecting Alu-mediated deletions.\n",
        "This notebook identifies, validates, and characterizes Alu specialist atoms using:\n",
        "- Statistical bias analysis\n",
        "- UCSC RepeatMasker validation\n",
        "- Genomic pattern analysis\n",
        "- Biological interpretation"
      ],
      "metadata": {
        "id": "CFK_co6wCEfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter, defaultdict\n",
        "import time\n",
        "import requests\n",
        "import json\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2_contingency, fisher_exact, mannwhitneyu\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration\n",
        "processed_dir = \"../data/processed\"\n",
        "models_dir = \"../data/models\"\n",
        "figures_dir = \"../figures\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {device}\")"
      ],
      "metadata": {
        "id": "WKMpMCOFCdVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SAE Results and Statistics\n",
        "\n",
        "# Load the  data from previous notebooks\n",
        "print(\"Loading SAE analysis results...\")\n",
        "\n",
        "# Load SAE embeddings and metadata\n",
        "sae_data = torch.load(f\"{processed_dir}/sae_sv_embeddings.pt\", map_location=device)\n",
        "test_sv_info = sae_data[\"sv_info\"]\n",
        "print(f\"Loaded {len(test_sv_info)} SV samples\")\n",
        "\n",
        "# Load atom statistics from interpretability analysis\n",
        "try:\n",
        "    stats_df = pd.read_csv(f\"{models_dir}/sae_atom_statistics.csv\")\n",
        "    print(f\"Loaded statistics for {len(stats_df)} atoms\")\n",
        "except FileNotFoundError:\n",
        "    print(\"SAE statistics not found - run interpretability analysis first\")\n",
        "    stats_df = None\n",
        "\n",
        "# Load SAE activations (assuming they exist from training)\n",
        "try:\n",
        "    acts = torch.load(f\"{models_dir}/sae_activations.pt\", map_location=device)\n",
        "    labels = torch.load(f\"{models_dir}/sae_labels.pt\", map_location=device)\n",
        "    print(f\"Loaded activations: {acts.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"SAE activations not found\")"
      ],
      "metadata": {
        "id": "3jBU9ApFCloL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1MlJ0pEB301"
      },
      "outputs": [],
      "source": [
        "## Identify Alu Specialist Candidates\n",
        "\n",
        "def identify_alu_specialist_candidates(stats_df, test_sv_info, acts, labels, min_activations=15):\n",
        "    \"\"\"\n",
        "    Identify atoms that are potential Alu deletion specialists based on:\n",
        "    1. Strong deletion bias (>70% deletions)\n",
        "    2. Alu-appropriate size clustering (250-350bp)\n",
        "    3. Sufficient statistical evidence\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"IDENTIFYING ALU SPECIALIST CANDIDATES\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    if stats_df is None or acts is None:\n",
        "        print(\"Missing required data\")\n",
        "        return {}\n",
        "\n",
        "    candidates = {}\n",
        "\n",
        "    # Get atoms with sufficient support\n",
        "    valid_atoms = stats_df[stats_df['support'] >= min_activations]['atom'].values\n",
        "    print(f\"Analyzing {len(valid_atoms)} atoms with ≥{min_activations} activations\")\n",
        "\n",
        "    for atom_id in valid_atoms:\n",
        "        # Get variants that activate this atom\n",
        "        firing_mask = (acts == atom_id).any(dim=1)\n",
        "        firing_indices = torch.where(firing_mask)[0].cpu().numpy()\n",
        "\n",
        "        if len(firing_indices) == 0:\n",
        "            continue\n",
        "\n",
        "        # Extract variant information\n",
        "        atom_variants = [test_sv_info[idx] for idx in firing_indices]\n",
        "\n",
        "        # Analyze characteristics\n",
        "        analysis = analyze_alu_potential(atom_id, atom_variants, stats_df)\n",
        "\n",
        "        # Check Alu specialist criteria\n",
        "        if meets_alu_criteria(analysis):\n",
        "            candidates[atom_id] = analysis\n",
        "            print(f\"✓ Atom {atom_id}: {analysis['alu_score']:.1f} Alu score\")\n",
        "\n",
        "    print(f\"\\n Found {len(candidates)} Alu specialist candidates\")\n",
        "    return candidates\n",
        "\n",
        "def analyze_alu_potential(atom_id, variants, stats_df):\n",
        "    \"\"\"Analyze potential for Alu-mediated deletion detection\"\"\"\n",
        "\n",
        "    if not variants:\n",
        "        return {'atom_id': atom_id, 'alu_score': 0}\n",
        "\n",
        "    # Extract characteristics\n",
        "    sizes = [abs(v.get('svlen', 0)) for v in variants]\n",
        "    types = [v.get('svtype', 'UNK') for v in variants]\n",
        "    truvari_classes = [v.get('truvari_class', 'UNK') for v in variants]\n",
        "\n",
        "    # Get atom statistics\n",
        "    atom_stats = stats_df[stats_df['atom'] == atom_id].iloc[0]\n",
        "\n",
        "    analysis = {\n",
        "        'atom_id': atom_id,\n",
        "        'total_variants': len(variants),\n",
        "        'sizes': sizes,\n",
        "        'types': types,\n",
        "        'truvari_classes': truvari_classes,\n",
        "        'odds_ratio': atom_stats['odds'],\n",
        "        'p_value': atom_stats['p'],\n",
        "        'support': atom_stats['support']\n",
        "    }\n",
        "\n",
        "    # Calculate Alu-specific metrics\n",
        "    deletions = sum(1 for t in types if t == 'DEL')\n",
        "    deletion_rate = deletions / len(variants)\n",
        "\n",
        "    alu_sized = sum(1 for s in sizes if 250 <= s <= 350)\n",
        "    alu_sized_rate = alu_sized / len(variants)\n",
        "\n",
        "    optimal_alu = sum(1 for s in sizes if 290 <= s <= 310)\n",
        "    optimal_alu_rate = optimal_alu / len(variants)\n",
        "\n",
        "    median_size = np.median(sizes) if sizes else 0\n",
        "    size_cv = np.std(sizes) / np.mean(sizes) if sizes and np.mean(sizes) > 0 else float('inf')\n",
        "\n",
        "    tp_count = sum(1 for tc in truvari_classes if tc in ['TP', 'tp_comp_vcf'])\n",
        "    tp_rate = tp_count / len(variants)\n",
        "\n",
        "    # Calculate Alu score\n",
        "    alu_score = 0\n",
        "\n",
        "    # Deletion bias (max 3 points)\n",
        "    if deletion_rate > 0.8:\n",
        "        alu_score += 3\n",
        "    elif deletion_rate > 0.6:\n",
        "        alu_score += 2\n",
        "    elif deletion_rate > 0.4:\n",
        "        alu_score += 1\n",
        "\n",
        "    # Size clustering (max 4 points)\n",
        "    if alu_sized_rate > 0.7:\n",
        "        alu_score += 4\n",
        "    elif alu_sized_rate > 0.5:\n",
        "        alu_score += 3\n",
        "    elif alu_sized_rate > 0.3:\n",
        "        alu_score += 2\n",
        "\n",
        "    # Optimal size enrichment (max 2 points)\n",
        "    if optimal_alu_rate > 0.3:\n",
        "        alu_score += 2\n",
        "    elif optimal_alu_rate > 0.15:\n",
        "        alu_score += 1\n",
        "\n",
        "    # Size precision (max 1 point)\n",
        "    if 280 <= median_size <= 320 and size_cv < 0.4:\n",
        "        alu_score += 1\n",
        "\n",
        "    analysis.update({\n",
        "        'deletion_count': deletions,\n",
        "        'deletion_rate': deletion_rate,\n",
        "        'alu_sized_count': alu_sized,\n",
        "        'alu_sized_rate': alu_sized_rate,\n",
        "        'optimal_alu_count': optimal_alu,\n",
        "        'optimal_alu_rate': optimal_alu_rate,\n",
        "        'median_size': median_size,\n",
        "        'size_cv': size_cv,\n",
        "        'tp_count': tp_count,\n",
        "        'tp_rate': tp_rate,\n",
        "        'alu_score': alu_score\n",
        "    })\n",
        "\n",
        "    return analysis\n",
        "\n",
        "def meets_alu_criteria(analysis, min_score=5):\n",
        "    \"\"\"Check if atom meets Alu specialist criteria\"\"\"\n",
        "    return (\n",
        "        analysis['alu_score'] >= min_score and\n",
        "        analysis['deletion_rate'] > 0.5 and\n",
        "        analysis['alu_sized_rate'] > 0.3\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run candidate identification\n",
        "if stats_df is not None and acts is not None:\n",
        "    alu_candidates = identify_alu_specialist_candidates(stats_df, test_sv_info, acts, labels)"
      ],
      "metadata": {
        "id": "J2U7NxkIKJUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UCSC RepeatMasker Validation\n",
        "\n",
        "def query_ucsc_repeatmasker(chrom, start, end, max_retries=3):\n",
        "    \"\"\"Query UCSC RepeatMasker track for repeat annotations\"\"\"\n",
        "\n",
        "    url = \"https://api.genome.ucsc.edu/getData/track\"\n",
        "    params = {\n",
        "        'genome': 'hg38',\n",
        "        'track': 'rmsk',\n",
        "        'chrom': chrom,\n",
        "        'start': start,\n",
        "        'end': end\n",
        "    }\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = requests.get(url, params=params, timeout=30)\n",
        "            if response.status_code == 200:\n",
        "                return response.json().get('rmsk', [])\n",
        "            else:\n",
        "                print(f\"API error {response.status_code}\")\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Request failed (attempt {attempt + 1}): {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(2 ** attempt)  # Exponential backoff\n",
        "\n",
        "    return []\n",
        "\n",
        "def analyze_alu_overlap(sv_info, repeatmasker_hits):\n",
        "    \"\"\"Analyze if SV overlaps with Alu elements\"\"\"\n",
        "\n",
        "    sv_start = sv_info.get('pos', 0)\n",
        "    sv_end = sv_start + abs(sv_info.get('svlen', 0))\n",
        "\n",
        "    alu_hits = []\n",
        "    for hit in repeatmasker_hits:\n",
        "        # Check if it's an Alu element\n",
        "        if (hit.get('repClass') == 'SINE' and\n",
        "            hit.get('repFamily') == 'Alu'):\n",
        "\n",
        "            hit_start = hit.get('genoStart', 0)\n",
        "            hit_end = hit.get('genoEnd', 0)\n",
        "\n",
        "            # Check for overlap or proximity (within 100bp)\n",
        "            distance = min(\n",
        "                abs(sv_start - hit_end),\n",
        "                abs(sv_end - hit_start)\n",
        "            )\n",
        "            overlap = max(0, min(sv_end, hit_end) - max(sv_start, hit_start))\n",
        "\n",
        "            if overlap > 0 or distance <= 100:\n",
        "                alu_hits.append({\n",
        "                    'repName': hit.get('repName', ''),\n",
        "                    'repFamily': hit.get('repFamily', ''),\n",
        "                    'strand': hit.get('strand', ''),\n",
        "                    'genoStart': hit_start,\n",
        "                    'genoEnd': hit_end,\n",
        "                    'overlap': overlap,\n",
        "                    'distance': distance,\n",
        "                    'swScore': hit.get('swScore', 0)\n",
        "                })\n",
        "\n",
        "    return {\n",
        "        'validated': len(alu_hits) > 0,\n",
        "        'alu_count': len(alu_hits),\n",
        "        'primary_subfamily': alu_hits[0]['repName'] if alu_hits else 'None',\n",
        "        'all_hits': alu_hits\n",
        "    }\n",
        "\n",
        "def validate_alu_candidates_with_repeatmasker(candidates, test_sv_info, acts, max_per_atom=50):\n",
        "    \"\"\"Validate Alu candidates using UCSC RepeatMasker\"\"\"\n",
        "\n",
        "    print(\"UCSC REPEATMASKER VALIDATION\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    validation_results = {}\n",
        "\n",
        "    for atom_id in candidates.keys():\n",
        "        print(f\"\\n Validating Atom {atom_id}\")\n",
        "\n",
        "        # Get variants that activate this atom\n",
        "        firing_mask = (acts == atom_id).any(dim=1)\n",
        "        firing_indices = torch.where(firing_mask)[0].cpu().numpy()\n",
        "\n",
        "        # Limit to reasonable number for API\n",
        "        if len(firing_indices) > max_per_atom:\n",
        "            firing_indices = np.random.choice(firing_indices, max_per_atom, replace=False)\n",
        "\n",
        "        atom_validations = []\n",
        "\n",
        "        for i, idx in enumerate(firing_indices):\n",
        "            sv = test_sv_info[idx]\n",
        "\n",
        "            # Query RepeatMasker with ±200bp window\n",
        "            window_start = max(0, sv.get('pos', 0) - 200)\n",
        "            window_end = sv.get('pos', 0) + abs(sv.get('svlen', 0)) + 200\n",
        "\n",
        "            print(f\"\\r   Processing {i+1}/{len(firing_indices)}: {sv.get('chrom')}:{sv.get('pos')}\", end=\"\")\n",
        "\n",
        "            try:\n",
        "                repeatmasker_hits = query_ucsc_repeatmasker(\n",
        "                    sv.get('chrom', ''), window_start, window_end\n",
        "                )\n",
        "\n",
        "                validation = analyze_alu_overlap(sv, repeatmasker_hits)\n",
        "                validation.update({\n",
        "                    'variant_idx': int(idx),\n",
        "                    'chrom': sv.get('chrom'),\n",
        "                    'pos': sv.get('pos'),\n",
        "                    'svlen': sv.get('svlen'),\n",
        "                    'svtype': sv.get('svtype'),\n",
        "                    'truvari_class': sv.get('truvari_class')\n",
        "                })\n",
        "\n",
        "                atom_validations.append(validation)\n",
        "\n",
        "                # Rate limiting\n",
        "                time.sleep(0.3)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\" [Error: {e}]\", end=\"\")\n",
        "                continue\n",
        "\n",
        "        validation_results[atom_id] = atom_validations\n",
        "\n",
        "        # Calculate validation rate\n",
        "        validated_count = sum(1 for v in atom_validations if v['validated'])\n",
        "        validation_rate = validated_count / len(atom_validations) * 100 if atom_validations else 0\n",
        "\n",
        "        print(f\"\\n    Validation rate: {validation_rate:.1f}% ({validated_count}/{len(atom_validations)})\")\n",
        "\n",
        "    return validation_results"
      ],
      "metadata": {
        "id": "KaRiuaNQKOAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run validation\n",
        "validation_results = validate_alu_candidates_with_repeatmasker(alu_candidates, test_sv_info, acts)"
      ],
      "metadata": {
        "id": "x1uyoSAqKQmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical Analysis of Validation Results\n",
        "\n",
        "def analyze_validation_statistics(validation_results, alu_candidates):\n",
        "    \"\"\"Comprehensive statistical analysis of validation results\"\"\"\n",
        "\n",
        "    print(\"STATISTICAL VALIDATION ANALYSIS\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Overall validation rates\n",
        "    validation_stats = {}\n",
        "\n",
        "    for atom_id, validations in validation_results.items():\n",
        "        if not validations:\n",
        "            continue\n",
        "\n",
        "        validated_count = sum(1 for v in validations if v['validated'])\n",
        "        total_count = len(validations)\n",
        "        validation_rate = validated_count / total_count\n",
        "\n",
        "        # Binomial confidence interval\n",
        "        from statsmodels.stats.proportion import proportion_confint\n",
        "        ci_low, ci_high = proportion_confint(validated_count, total_count, alpha=0.05)\n",
        "\n",
        "        validation_stats[atom_id] = {\n",
        "            'validated': validated_count,\n",
        "            'total': total_count,\n",
        "            'rate': validation_rate,\n",
        "            'ci_low': ci_low,\n",
        "            'ci_high': ci_high,\n",
        "            'alu_score': alu_candidates[atom_id]['alu_score']\n",
        "        }\n",
        "\n",
        "        print(f\"Atom {atom_id}: {validation_rate:.1%} validated ({validated_count}/{total_count})\")\n",
        "        print(f\"   95% CI: [{ci_low:.1%}, {ci_high:.1%}]\")\n",
        "        print(f\"   Alu Score: {alu_candidates[atom_id]['alu_score']:.1f}\")\n",
        "\n",
        "    # Subfamily analysis\n",
        "    print(f\"\\n ALU SUBFAMILY DISTRIBUTION:\")\n",
        "\n",
        "    all_subfamilies = []\n",
        "    for validations in validation_results.values():\n",
        "        for v in validations:\n",
        "            if v['validated'] and v['primary_subfamily'] != 'None':\n",
        "                all_subfamilies.append(v['primary_subfamily'])\n",
        "\n",
        "    subfamily_counts = Counter(all_subfamilies)\n",
        "    for subfamily, count in subfamily_counts.most_common():\n",
        "        percentage = count / len(all_subfamilies) * 100 if all_subfamilies else 0\n",
        "        print(f\"   {subfamily}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "    return validation_stats, subfamily_counts\n",
        "\n",
        "# Run statistical analysis\n",
        "validation_stats, subfamily_counts = analyze_validation_statistics(validation_results, alu_candidates)\n"
      ],
      "metadata": {
        "id": "QOzhSL3HKUUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of Results\n",
        "\n",
        "def create_alu_analysis_visualizations(alu_candidates, validation_results, validation_stats):\n",
        "    \"\"\"Create comprehensive visualizations of Alu analysis\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    fig.suptitle('SAE Alu Specialist Analysis Results', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. Alu scores by atom\n",
        "    ax = axes[0, 0]\n",
        "    atom_ids = list(alu_candidates.keys())\n",
        "    alu_scores = [alu_candidates[aid]['alu_score'] for aid in atom_ids]\n",
        "\n",
        "    bars = ax.bar([f'A{aid}' for aid in atom_ids], alu_scores,\n",
        "                  color='lightcoral', alpha=0.7, edgecolor='black')\n",
        "    ax.set_ylabel('Alu Specialist Score')\n",
        "    ax.set_title('Alu Specialist Scores by Atom')\n",
        "    ax.set_ylim(0, 10)\n",
        "\n",
        "    # Add score labels\n",
        "    for bar, score in zip(bars, alu_scores):\n",
        "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
        "               f'{score:.1f}', ha='center', va='bottom')\n",
        "\n",
        "    # 2. Validation rates\n",
        "    ax = axes[0, 1]\n",
        "    val_atoms = list(validation_stats.keys())\n",
        "    val_rates = [validation_stats[aid]['rate'] for aid in val_atoms]\n",
        "\n",
        "    bars = ax.bar([f'A{aid}' for aid in val_atoms], val_rates,\n",
        "                  color='lightblue', alpha=0.7, edgecolor='black')\n",
        "    ax.set_ylabel('Validation Rate')\n",
        "    ax.set_title('RepeatMasker Validation Rates')\n",
        "    ax.set_ylim(0, 1)\n",
        "\n",
        "    # Add confidence intervals\n",
        "    for i, (bar, aid) in enumerate(zip(bars, val_atoms)):\n",
        "        ci_low = validation_stats[aid]['ci_low']\n",
        "        ci_high = validation_stats[aid]['ci_high']\n",
        "        ax.errorbar(bar.get_x() + bar.get_width()/2, bar.get_height(),\n",
        "                   yerr=[[bar.get_height() - ci_low], [ci_high - bar.get_height()]],\n",
        "                   fmt='none', color='black', capsize=3)\n",
        "\n",
        "    # 3. Score vs validation correlation\n",
        "    ax = axes[0, 2]\n",
        "    scores_for_corr = [alu_candidates[aid]['alu_score'] for aid in val_atoms]\n",
        "    ax.scatter(scores_for_corr, val_rates, s=100, alpha=0.7, color='green')\n",
        "\n",
        "    # Add trend line\n",
        "    if len(scores_for_corr) > 1:\n",
        "        z = np.polyfit(scores_for_corr, val_rates, 1)\n",
        "        p = np.poly1d(z)\n",
        "        ax.plot(scores_for_corr, p(scores_for_corr), \"r--\", alpha=0.8)\n",
        "\n",
        "    ax.set_xlabel('Alu Specialist Score')\n",
        "    ax.set_ylabel('Validation Rate')\n",
        "    ax.set_title('Score vs Validation Correlation')\n",
        "\n",
        "    # Add atom labels\n",
        "    for score, rate, aid in zip(scores_for_corr, val_rates, val_atoms):\n",
        "        ax.annotate(f'A{aid}', (score, rate), xytext=(5, 5),\n",
        "                   textcoords='offset points', fontsize=8)\n",
        "\n",
        "    # 4. Size distributions for top candidate\n",
        "    ax = axes[1, 0]\n",
        "    if alu_candidates:\n",
        "        top_atom = max(alu_candidates.keys(), key=lambda x: alu_candidates[x]['alu_score'])\n",
        "\n",
        "        if 'sizes' in alu_candidates[top_atom]:\n",
        "            sizes = alu_candidates[top_atom]['sizes']\n",
        "            ax.hist(sizes, bins=30, alpha=0.7, color='orange', edgecolor='black')\n",
        "            ax.axvspan(250, 350, alpha=0.3, color='red', label='Alu Range')\n",
        "            ax.axvspan(290, 310, alpha=0.4, color='darkred', label='Optimal Alu')\n",
        "            ax.set_xlabel('SV Size (bp)')\n",
        "            ax.set_ylabel('Count')\n",
        "            ax.set_title(f'Size Distribution - Atom {top_atom}')\n",
        "            ax.legend()\n",
        "\n",
        "    # 5. Subfamily distribution\n",
        "    ax = axes[1, 1]\n",
        "    if subfamily_counts:\n",
        "        subfamilies, counts = zip(*subfamily_counts.most_common()[:8])\n",
        "        ax.pie(counts, labels=subfamilies, autopct='%1.1f%%', startangle=90)\n",
        "        ax.set_title('Alu Subfamily Distribution')\n",
        "\n",
        "    # 6. Validation summary table\n",
        "    ax = axes[1, 2]\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Create summary table\n",
        "    table_data = []\n",
        "    for aid in validation_stats.keys():\n",
        "        stats = validation_stats[aid]\n",
        "        table_data.append([\n",
        "            f'Atom {aid}',\n",
        "            f'{stats[\"rate\"]:.1%}',\n",
        "            f'{stats[\"validated\"]}/{stats[\"total\"]}',\n",
        "            f'{alu_candidates[aid][\"alu_score\"]:.1f}'\n",
        "        ])\n",
        "\n",
        "    if table_data:\n",
        "        table = ax.table(cellText=table_data,\n",
        "                        colLabels=['Atom', 'Val Rate', 'Count', 'Score'],\n",
        "                        cellLoc='center',\n",
        "                        loc='center')\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1, 1.5)\n",
        "        ax.set_title('Validation Summary', pad=20)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{figures_dir}/alu_specialist_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Create visualizations\n",
        "create_alu_analysis_visualizations(alu_candidates, validation_results, validation_stats)"
      ],
      "metadata": {
        "id": "bVdFl_yOKfUn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
