{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Traditional Machine Learning for SV Classification\n",
        "\n",
        "This notebook trains Random Forest, XGBoost, and Logistic Regression models\n",
        "using the 15 genomic features for TP vs FP classification.\n",
        "\n",
        "Input:\n",
        "- CSV files with computed features\n",
        "\n",
        "Output:\n",
        "- Model performance comparison\n",
        "- Feature importance analysis\n",
        "- Classification results\n",
        "\n",
        "Models tested:\n",
        "- Random Forest, XGBoost, Logistic Regression (with different feature selection approaches)"
      ],
      "metadata": {
        "id": "jUR8embmTt-8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KgxzlerTqe3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, confusion_matrix\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df = pd.read_csv('../data/processed/SV_Features_Dataset.csv')\n",
        "\n",
        "# Define features\n",
        "FEATURES = [\n",
        "    'log_svlen', 'depth_ratio', 'depth_mad', 'ab', 'cn_slop',\n",
        "    'mq_drop', 'clip_frac', 'split_reads', 'read_len_med', 'strand_bias',\n",
        "    'gc_frac', 'homopolymer_max', 'lcr_mask',\n",
        "    'support_read', 'svtype_DEL'\n",
        "]\n",
        "\n",
        "# Prepare data\n",
        "X = df[FEATURES].fillna(df[FEATURES].median())\n",
        "y = (df['label'] == 'TP').astype(int)\n",
        "\n",
        "print(f\"Data shape: {X.shape}\")\n",
        "print(f\"Class balance: {y.mean():.3f} TP, {1-y.mean():.3f} FP\")\n",
        "print(f\"Features: {len(FEATURES)}\")"
      ],
      "metadata": {
        "id": "Iv9XoommT3eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
        "    'Logistic Regression': LogisticRegression(random_state=42)\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "print(\"All Features Results:\")\n",
        "print(f\"{'Model':<20} {'CV AUC':<10} {'Test AUC':<10} {'Test Precision':<15} {'Test Recall':<12} {'Test F1':<10}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Use scaled data for LR, unscaled for tree methods\n",
        "    if 'Regression' in name:\n",
        "        X_train_use = X_train_scaled\n",
        "        X_test_use = X_test_scaled\n",
        "    else:\n",
        "        X_train_use = X_train\n",
        "        X_test_use = X_test\n",
        "\n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(model, X_train_use, y_train, cv=StratifiedKFold(5), scoring='roc_auc')\n",
        "\n",
        "    # Fit and predict\n",
        "    model.fit(X_train_use, y_train)\n",
        "    y_pred = model.predict(X_test_use)\n",
        "    y_pred_proba = model.predict_proba(X_test_use)[:, 1]\n",
        "\n",
        "    # Metrics\n",
        "    test_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    precision = report['1']['precision']\n",
        "    recall = report['1']['recall']\n",
        "    f1 = report['1']['f1-score']\n",
        "\n",
        "    results.append({\n",
        "        'Model': f'{name} (All)',\n",
        "        'Features': len(FEATURES),\n",
        "        'CV_AUC': cv_scores.mean(),\n",
        "        'CV_Std': cv_scores.std(),\n",
        "        'Test_AUC': test_auc,\n",
        "        'Test_Precision': precision,\n",
        "        'Test_Recall': recall,\n",
        "        'Test_F1': f1\n",
        "    })\n",
        "\n",
        "    print(f\"{name:<20} {cv_scores.mean():<10.3f} {test_auc:<10.3f} {precision:<15.3f} {recall:<12.3f} {f1:<10.3f}\")"
      ],
      "metadata": {
        "id": "YfL8_3-HT76I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test different numbers of top features\n",
        "for k in [6, 8, 10]:\n",
        "    if k > len(FEATURES):\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nTop {k} Features Results:\")\n",
        "\n",
        "    # Select top k features\n",
        "    selector = SelectKBest(score_func=f_classif, k=k)\n",
        "    X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
        "    X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "    # Get selected feature names\n",
        "    selected_features = [FEATURES[i] for i in selector.get_support(indices=True)]\n",
        "    print(f\"Selected features: {selected_features}\")\n",
        "\n",
        "    print(f\"{'Model':<20} {'CV AUC':<10} {'Test AUC':<10} {'Test Precision':<15} {'Test Recall':<12} {'Test F1':<10}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for name, model in models.items():\n",
        "        # Use selected features for all models\n",
        "        cv_scores = cross_val_score(model, X_train_selected, y_train, cv=StratifiedKFold(5), scoring='roc_auc')\n",
        "\n",
        "        model.fit(X_train_selected, y_train)\n",
        "        y_pred = model.predict(X_test_selected)\n",
        "        y_pred_proba = model.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "        test_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "        report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "        precision = report['1']['precision']\n",
        "        recall = report['1']['recall']\n",
        "        f1 = report['1']['f1-score']\n",
        "\n",
        "        results.append({\n",
        "            'Model': f'{name} (Top {k})',\n",
        "            'Features': k,\n",
        "            'CV_AUC': cv_scores.mean(),\n",
        "            'CV_Std': cv_scores.std(),\n",
        "            'Test_AUC': test_auc,\n",
        "            'Test_Precision': precision,\n",
        "            'Test_Recall': recall,\n",
        "            'Test_F1': f1\n",
        "        })\n",
        "\n",
        "        print(f\"{name:<20} {cv_scores.mean():<10.3f} {test_auc:<10.3f} {precision:<15.3f} {recall:<12.3f} {f1:<10.3f}\")"
      ],
      "metadata": {
        "id": "0tBtVFnWT-z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test PCA with different numbers of components\n",
        "for n_components in [6, 8, 10]:\n",
        "    if n_components > len(FEATURES):\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nPCA {n_components} Components Results:\")\n",
        "\n",
        "    pca = PCA(n_components=n_components)\n",
        "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "    X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "    print(f\"Explained variance ratio: {pca.explained_variance_ratio_.sum():.3f}\")\n",
        "\n",
        "    print(f\"{'Model':<20} {'CV AUC':<10} {'Test AUC':<10} {'Test Precision':<15} {'Test Recall':<12} {'Test F1':<10}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for name, model in models.items():\n",
        "        cv_scores = cross_val_score(model, X_train_pca, y_train, cv=StratifiedKFold(5), scoring='roc_auc')\n",
        "\n",
        "        model.fit(X_train_pca, y_train)\n",
        "        y_pred = model.predict(X_test_pca)\n",
        "        y_pred_proba = model.predict_proba(X_test_pca)[:, 1]\n",
        "\n",
        "        test_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "        report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "        precision = report['1']['precision']\n",
        "        recall = report['1']['recall']\n",
        "        f1 = report['1']['f1-score']\n",
        "\n",
        "        results.append({\n",
        "            'Model': f'{name} (PCA {n_components})',\n",
        "            'Features': n_components,\n",
        "            'CV_AUC': cv_scores.mean(),\n",
        "            'CV_Std': cv_scores.std(),\n",
        "            'Test_AUC': test_auc,\n",
        "            'Test_Precision': precision,\n",
        "            'Test_Recall': recall,\n",
        "            'Test_F1': f1\n",
        "        })\n",
        "\n",
        "        print(f\"{name:<20} {cv_scores.mean():<10.3f} {test_auc:<10.3f} {precision:<15.3f} {recall:<12.3f} {f1:<10.3f}\")"
      ],
      "metadata": {
        "id": "TD7JfAwkUBPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrame and sort by Test F1\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values('Test_F1', ascending=False)\n",
        "\n",
        "print(\"\\nFinal Results Ranking (by Test F1):\")\n",
        "print(f\"{'Rank':<4} {'Model':<25} {'Test F1':<8} {'Test AUC':<10} {'CV AUC':<10} {'Features':<8}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for i, (_, row) in enumerate(results_df.head(10).iterrows(), 1):\n",
        "    print(f\"{i:<4} {row['Model']:<25} {row['Test_F1']:<8.3f} {row['Test_AUC']:<10.3f} {row['CV_AUC']:<10.3f} {row['Features']:<8}\")\n",
        "\n",
        "# Best model\n",
        "best = results_df.iloc[0]\n",
        "print(f\"\\nBest Model: {best['Model']}\")\n",
        "print(f\"Test F1: {best['Test_F1']:.3f}\")\n",
        "print(f\"Test AUC: {best['Test_AUC']:.3f}\")\n",
        "print(f\"CV AUC: {best['CV_AUC']:.3f} Â± {best['CV_Std']:.3f}\")\n",
        "print(f\"Features: {best['Features']}\")\n",
        "\n",
        "# Save results\n",
        "results_df.to_csv('../data/processed/traditional_ml_results.csv', index=False)"
      ],
      "metadata": {
        "id": "BLsPa00BUD52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train best Random Forest model and get feature importance\n",
        "best_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "best_rf.fit(X_train, y_train)\n",
        "\n",
        "# Feature importance\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': FEATURES,\n",
        "    'importance': best_rf.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance (Random Forest):\")\n",
        "for _, row in importance_df.head(10).iterrows():\n",
        "    print(f\"{row['feature']:<18} {row['importance']:.4f}\")\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(range(len(importance_df)), importance_df['importance'])\n",
        "plt.yticks(range(len(importance_df)), importance_df['feature'])\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('Random Forest Feature Importance')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.savefig('../figures/feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Save feature importance\n",
        "importance_df.to_csv('../data/processed/feature_importance.csv', index=False)\n",
        "\n",
        "print(\"\\nTraditional ML analysis complete.\")\n",
        "print(\"Results saved to:\")\n",
        "print(\"  - ../data/processed/traditional_ml_results.csv\")\n",
        "print(\"  - ../data/processed/feature_importance.csv\")\n",
        "print(\"  - ../figures/feature_importance.png\")"
      ],
      "metadata": {
        "id": "skIskscyUGwM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}