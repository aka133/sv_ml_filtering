{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Self-supervised VICReg pre-trained ResNet50x2 for genomic structural variant classification."
      ],
      "metadata": {
        "id": "Z0OvgAKJMDXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Configuration - GitHub repository structure\n",
        "DATA_DIR = '../data/processed/all_datasets_images_rgb'\n",
        "SAVE_DIR = '../data/processed/vicreg_experiments'\n",
        "MODELS_DIR = '../data/processed/vicreg_experiments/models'\n",
        "FIGURES_DIR = '../figures'\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
        "\n",
        "# Standard hyperparameters\n",
        "VICREG_CONFIG = {\n",
        "    'learning_rate': 1e-4,\n",
        "    'batch_size': 32,\n",
        "    'weight_decay': 1e-4,\n",
        "    'dropout_rate': 0.2,\n",
        "    'epochs': 20,\n",
        "    'patience': 5,\n",
        "}"
      ],
      "metadata": {
        "id": "KJmgJQpaMJWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "\n",
        "class GenomicDataset(Dataset):\n",
        "    \"\"\"Dataset for genomic structural variant images\"\"\"\n",
        "\n",
        "    def __init__(self, data_list, transform=None):\n",
        "        self.data = data_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "\n",
        "        try:\n",
        "            # Load image\n",
        "            data = torch.load(item['filepath'], map_location='cpu')\n",
        "            if isinstance(data, dict):\n",
        "                image = data['image']\n",
        "            else:\n",
        "                image = data\n",
        "\n",
        "            # Handle channels (ensure RGB)\n",
        "            if image.shape[0] != 3:\n",
        "                if image.shape[0] < 3:\n",
        "                    padding = torch.zeros(3 - image.shape[0], *image.shape[1:])\n",
        "                    image = torch.cat([image, padding], dim=0)\n",
        "                else:\n",
        "                    image = image[:3]\n",
        "\n",
        "            # Normalize to [0,1]\n",
        "            if image.max() > 1:\n",
        "                image = image.float() / 255.0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {item['filepath']}: {e}\")\n",
        "            image = torch.zeros(3, 224, 224)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(transforms.ToPILImage()(image))\n",
        "\n",
        "        return image, torch.tensor(item['label'], dtype=torch.long)"
      ],
      "metadata": {
        "id": "-QQRyIhuMPfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading\n",
        "\n",
        "def load_all_genomic_data():\n",
        "    \"\"\"Load all genomic data files\"\"\"\n",
        "\n",
        "    print(\"Loading all genomic data...\")\n",
        "\n",
        "    all_data = []\n",
        "    datasets = ['HG002_GRCh37', 'HG002_GRCh38', 'HG005_GRCh38']\n",
        "\n",
        "    for dataset_name in datasets:\n",
        "        dataset_path = os.path.join(DATA_DIR, dataset_name)\n",
        "\n",
        "        if not os.path.exists(dataset_path):\n",
        "            print(f\"Missing dataset: {dataset_path}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Loading {dataset_name}...\")\n",
        "\n",
        "        filenames = [f for f in os.listdir(dataset_path) if f.endswith('.pt')]\n",
        "\n",
        "        tp_count = 0\n",
        "        fp_count = 0\n",
        "\n",
        "        for filename in tqdm(filenames, desc=f\"Processing {dataset_name}\"):\n",
        "            parts = filename[:-3].split('_')\n",
        "\n",
        "            if len(parts) >= 8:\n",
        "                try:\n",
        "                    label = parts[2]  # TP or FP\n",
        "                    svtype = parts[6]  # INS, DEL, etc.\n",
        "\n",
        "                    if label in ['TP', 'FP']:\n",
        "                        filepath = os.path.join(dataset_path, filename)\n",
        "\n",
        "                        all_data.append({\n",
        "                            'dataset': dataset_name,\n",
        "                            'filepath': filepath,\n",
        "                            'label_str': label,\n",
        "                            'svtype': svtype,\n",
        "                            'binary_label': 1 if label == 'TP' else 0,\n",
        "                            'multiclass_label': 0 if label == 'FP' else (1 if svtype == 'DEL' else 2)\n",
        "                        })\n",
        "\n",
        "                        if label == 'TP':\n",
        "                            tp_count += 1\n",
        "                        else:\n",
        "                            fp_count += 1\n",
        "\n",
        "                except (ValueError, IndexError):\n",
        "                    continue\n",
        "\n",
        "        print(f\"   {tp_count} TP, {fp_count} FP = {tp_count + fp_count} total\")\n",
        "\n",
        "    print(f\"\\nTotal dataset:\")\n",
        "    print(f\"   Samples: {len(all_data)}\")\n",
        "\n",
        "    # Count labels\n",
        "    tp_total = sum(1 for x in all_data if x['label_str'] == 'TP')\n",
        "    fp_total = sum(1 for x in all_data if x['label_str'] == 'FP')\n",
        "\n",
        "    print(f\"   TP: {tp_total} ({100*tp_total/len(all_data):.1f}%)\")\n",
        "    print(f\"   FP: {fp_total} ({100*fp_total/len(all_data):.1f}%)\")\n",
        "\n",
        "    # Count SV types in TP\n",
        "    from collections import Counter\n",
        "    svtype_counts = Counter(x['svtype'] for x in all_data if x['label_str'] == 'TP')\n",
        "    print(f\"   SV types: {dict(svtype_counts)}\")\n",
        "\n",
        "    return all_data\n",
        "\n",
        "def create_data_splits(all_data):\n",
        "    \"\"\"Create both 80/20 and leave-one-genome-out splits\"\"\"\n",
        "\n",
        "    splits = {}\n",
        "\n",
        "    # 1. Random 80/20 split\n",
        "    print(\"\\nCreating 80/20 split...\")\n",
        "    train_80, test_20 = train_test_split(\n",
        "        all_data,\n",
        "        test_size=0.2,\n",
        "        stratify=[x['label_str'] for x in all_data],\n",
        "        random_state=42\n",
        "    )\n",
        "    splits['80_20'] = {'train': train_80, 'test': test_20}\n",
        "    print(f\"   Train: {len(train_80)}, Test: {len(test_20)}\")\n",
        "\n",
        "    # 2. Leave-one-genome-out splits\n",
        "    print(\"\\nCreating leave-one-genome-out splits...\")\n",
        "    genomes = ['HG002_GRCh37', 'HG002_GRCh38', 'HG005_GRCh38']\n",
        "\n",
        "    for test_genome in genomes:\n",
        "        train_data = [x for x in all_data if x['dataset'] != test_genome]\n",
        "        test_data = [x for x in all_data if x['dataset'] == test_genome]\n",
        "\n",
        "        splits[f'holdout_{test_genome}'] = {'train': train_data, 'test': test_data}\n",
        "        print(f\"   {test_genome}: Train={len(train_data)}, Test={len(test_data)}\")\n",
        "\n",
        "    return splits\n",
        "\n",
        "def create_transforms():\n",
        "    \"\"\"Standard ImageNet transforms\"\"\"\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.458, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.458, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    return train_transform, test_transform\n"
      ],
      "metadata": {
        "id": "qtBbfybcMTjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VICReg model class\n",
        "\n",
        "class VICRegResNet(nn.Module):\n",
        "    \"\"\"VICReg pre-trained ResNet50x2 for genomic classification\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, dropout=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        print(\"Loading Facebook's VICReg ResNet50x2...\")\n",
        "\n",
        "        try:\n",
        "            # Load Facebook's pre-trained VICReg model\n",
        "            self.backbone = torch.hub.load('facebookresearch/vicreg:main', 'resnet50x2', pretrained=True)\n",
        "            print(\"   Successfully loaded VICReg ResNet50x2\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   Failed to load VICReg model: {e}\")\n",
        "            print(\"   Falling back to standard Wide ResNet50-2...\")\n",
        "            self.backbone = torchvision.models.wide_resnet50_2(weights='IMAGENET1K_V1')\n",
        "\n",
        "        # Get feature dimension - VICReg ResNet50x2 outputs 4096 features\n",
        "        feature_dim = 4096\n",
        "\n",
        "        # Remove original classifier\n",
        "        if hasattr(self.backbone, 'fc'):\n",
        "            self.backbone.fc = nn.Identity()\n",
        "        elif hasattr(self.backbone, 'head'):\n",
        "            self.backbone.head = nn.Identity()\n",
        "\n",
        "        # Freeze backbone\n",
        "        print(\"Freezing VICReg backbone...\")\n",
        "        for param in self.backbone.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Trainable classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(feature_dim, num_classes)\n",
        "        )\n",
        "\n",
        "        # Count parameters\n",
        "        total_params = sum(p.numel() for p in self.parameters())\n",
        "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "        print(f\"   VICReg Model: {total_params:,} total, {trainable_params:,} trainable\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            features = self.backbone(x)\n",
        "        return self.classifier(features)"
      ],
      "metadata": {
        "id": "SzYyA4l2MWXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "\n",
        "def train_vicreg_model(num_classes, train_data, test_data, experiment_name):\n",
        "    \"\"\"Train a single VICReg model and save it\"\"\"\n",
        "\n",
        "    print(f\"\\nTraining VICReg ({num_classes}-class) - {experiment_name}\")\n",
        "\n",
        "    # Create model save directory\n",
        "    model_save_dir = os.path.join(MODELS_DIR, experiment_name)\n",
        "    os.makedirs(model_save_dir, exist_ok=True)\n",
        "    print(f\"Model will be saved to: {model_save_dir}\")\n",
        "\n",
        "    # Create transforms and datasets\n",
        "    train_transform, test_transform = create_transforms()\n",
        "\n",
        "    # Set label key based on num_classes\n",
        "    label_key = 'binary_label' if num_classes == 2 else 'multiclass_label'\n",
        "\n",
        "    # Update data with correct labels\n",
        "    train_data_labeled = [{**item, 'label': item[label_key]} for item in train_data]\n",
        "    test_data_labeled = [{**item, 'label': item[label_key]} for item in test_data]\n",
        "\n",
        "    train_dataset = GenomicDataset(train_data_labeled, train_transform)\n",
        "    test_dataset = GenomicDataset(test_data_labeled, test_transform)\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=VICREG_CONFIG['batch_size'],\n",
        "                             shuffle=True, num_workers=4, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=VICREG_CONFIG['batch_size'],\n",
        "                            shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    # Model\n",
        "    model = VICRegResNet(num_classes, VICREG_CONFIG['dropout_rate']).to(device)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=VICREG_CONFIG['learning_rate'],\n",
        "        weight_decay=VICREG_CONFIG['weight_decay']\n",
        "    )\n",
        "\n",
        "    # Scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='max', factor=0.5, patience=3, verbose=False\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    best_test_acc = 0\n",
        "    best_model_state = None\n",
        "    patience_counter = 0\n",
        "    history = []\n",
        "\n",
        "    for epoch in range(VICREG_CONFIG['epochs']):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        train_loss_total = 0\n",
        "\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = F.cross_entropy(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss_total += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_acc = 100. * train_correct / train_total\n",
        "        train_loss = train_loss_total / len(train_loader)\n",
        "\n",
        "        # Testing\n",
        "        model.eval()\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "        test_probs = []\n",
        "        test_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "\n",
        "                _, predicted = outputs.max(1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                # For AUC (binary only)\n",
        "                if num_classes == 2:\n",
        "                    probs = F.softmax(outputs, dim=1)\n",
        "                    test_probs.extend(probs[:, 1].cpu().numpy())\n",
        "                    test_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "        test_acc = 100. * test_correct / test_total\n",
        "        test_auc = roc_auc_score(test_targets, test_probs) if num_classes == 2 and len(set(test_targets)) > 1 else 0\n",
        "\n",
        "        scheduler.step(test_acc)\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        # Save best model state\n",
        "        if test_acc > best_test_acc:\n",
        "            best_test_acc = test_acc\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            patience_counter = 0\n",
        "            print(f\"   New best: {test_acc:.2f}% - Model state saved!\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        history.append({\n",
        "            'epoch': epoch + 1,\n",
        "            'train_acc': train_acc,\n",
        "            'test_acc': test_acc,\n",
        "            'test_auc': test_auc,\n",
        "            'train_loss': train_loss,\n",
        "            'lr': current_lr\n",
        "        })\n",
        "\n",
        "        print(f\"   Epoch {epoch+1}: Train={train_acc:.1f}%, Test={test_acc:.1f}%, AUC={test_auc:.3f}, LR={current_lr:.1e}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if patience_counter >= VICREG_CONFIG['patience']:\n",
        "            print(f\"   Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    # Save the best model to disk\n",
        "    checkpoint_path = None\n",
        "    if best_model_state is not None:\n",
        "        checkpoint = {\n",
        "            'model_state_dict': best_model_state,\n",
        "            'model_type': 'VICReg',\n",
        "            'num_classes': num_classes,\n",
        "            'experiment_name': experiment_name,\n",
        "            'best_test_acc': best_test_acc,\n",
        "            'final_test_auc': test_auc,\n",
        "            'config': VICREG_CONFIG,\n",
        "            'history': history,\n",
        "            'model_config': {\n",
        "                'feature_dim': 4096,\n",
        "                'dropout_rate': VICREG_CONFIG['dropout_rate']\n",
        "            }\n",
        "        }\n",
        "\n",
        "        checkpoint_path = os.path.join(model_save_dir, 'best_vicreg_model.pth')\n",
        "        torch.save(checkpoint, checkpoint_path)\n",
        "        print(f\"   Model saved to: {checkpoint_path}\")\n",
        "\n",
        "        # Save model info\n",
        "        info_path = os.path.join(model_save_dir, 'vicreg_model_info.json')\n",
        "        model_info = {\n",
        "            'experiment_name': experiment_name,\n",
        "            'model_type': 'VICReg',\n",
        "            'num_classes': num_classes,\n",
        "            'best_test_acc': best_test_acc,\n",
        "            'final_test_auc': test_auc,\n",
        "            'checkpoint_path': checkpoint_path,\n",
        "            'saved_at': datetime.now().isoformat()\n",
        "        }\n",
        "        with open(info_path, 'w') as f:\n",
        "            json.dump(model_info, f, indent=2)\n",
        "\n",
        "        print(f\"   Model info saved to: {info_path}\")\n",
        "\n",
        "    print(f\"   Best test accuracy: {best_test_acc:.2f}%\")\n",
        "\n",
        "    return {\n",
        "        'model_type': 'VICReg',\n",
        "        'num_classes': num_classes,\n",
        "        'experiment': experiment_name,\n",
        "        'best_test_acc': best_test_acc,\n",
        "        'final_test_auc': test_auc,\n",
        "        'history': history,\n",
        "        'model_path': checkpoint_path,\n",
        "        'model_save_dir': model_save_dir\n",
        "    }"
      ],
      "metadata": {
        "id": "9_rTIqVMMaJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading and analysis\n",
        "\n",
        "def load_saved_vicreg_model(checkpoint_path):\n",
        "    \"\"\"Load a saved VICReg model from checkpoint\"\"\"\n",
        "\n",
        "    print(f\"Loading VICReg model from: {checkpoint_path}\")\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
        "\n",
        "    # Recreate VICReg model\n",
        "    num_classes = checkpoint['num_classes']\n",
        "    dropout_rate = checkpoint['model_config']['dropout_rate']\n",
        "\n",
        "    model = VICRegResNet(num_classes, dropout_rate)\n",
        "\n",
        "    # Load weights\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "\n",
        "    print(f\"Loaded VICReg ({num_classes}-class)\")\n",
        "    print(f\"   Best accuracy: {checkpoint['best_test_acc']:.2f}%\")\n",
        "    print(f\"   Final AUC: {checkpoint['final_test_auc']:.3f}\")\n",
        "\n",
        "    return model, checkpoint\n",
        "\n",
        "\n",
        "def analyze_saved_vicreg_models():\n",
        "    \"\"\"Analyze all saved VICReg models\"\"\"\n",
        "\n",
        "    print(\"ANALYZING SAVED VICREG MODELS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    if not os.path.exists(MODELS_DIR):\n",
        "        print(\"No models directory found\")\n",
        "        return None\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for model_dir in os.listdir(MODELS_DIR):\n",
        "        model_path = os.path.join(MODELS_DIR, model_dir)\n",
        "        checkpoint_path = os.path.join(model_path, 'best_vicreg_model.pth')\n",
        "\n",
        "        if os.path.exists(checkpoint_path):\n",
        "            try:\n",
        "                checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
        "                results.append({\n",
        "                    'Model': 'VICReg-ResNet50x2',\n",
        "                    'Classes': f\"{checkpoint['num_classes']}-class\",\n",
        "                    'Split': checkpoint['experiment_name'].split('_')[-1] if '_' in checkpoint['experiment_name'] else 'unknown',\n",
        "                    'Accuracy': checkpoint['best_test_acc'],\n",
        "                    'AUC': checkpoint.get('final_test_auc', 0),\n",
        "                    'Full_Name': checkpoint['experiment_name']\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {model_dir}: {str(e)[:100]}...\")\n",
        "\n",
        "    if not results:\n",
        "        print(\"No saved VICReg models found!\")\n",
        "        return None\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    print(f\"Found {len(df)} saved VICReg models\")\n",
        "\n",
        "    # Performance table\n",
        "    print(f\"\\nTOP VICREG MODELS BY ACCURACY:\")\n",
        "    top_models = df.nlargest(10, 'Accuracy')[['Model', 'Classes', 'Split', 'Accuracy', 'AUC']]\n",
        "    print(top_models.to_string(index=False, float_format='%.2f'))\n",
        "\n",
        "    # Best by category\n",
        "    print(f\"\\nBEST BY CATEGORY:\")\n",
        "\n",
        "    # Best binary\n",
        "    binary_models = df[df['Classes'] == '2-class']\n",
        "    if len(binary_models) > 0:\n",
        "        binary_best = binary_models.nlargest(1, 'Accuracy').iloc[0]\n",
        "        print(f\"   Binary: {binary_best['Model']} ({binary_best['Split']}) - {binary_best['Accuracy']:.2f}%\")\n",
        "\n",
        "    # Best 3-class\n",
        "    multiclass_models = df[df['Classes'] == '3-class']\n",
        "    if len(multiclass_models) > 0:\n",
        "        multiclass_best = multiclass_models.nlargest(1, 'Accuracy').iloc[0]\n",
        "        print(f\"   3-class: {multiclass_best['Model']} ({multiclass_best['Split']}) - {multiclass_best['Accuracy']:.2f}%\")\n",
        "\n",
        "    # Overall champion\n",
        "    overall_best = df.nlargest(1, 'Accuracy').iloc[0]\n",
        "    print(f\"\\nOVERALL VICREG CHAMPION:\")\n",
        "    print(f\"   {overall_best['Full_Name']}: {overall_best['Accuracy']:.2f}% (AUC: {overall_best['AUC']:.3f})\")\n",
        "\n",
        "    # CSV-Filter comparison\n",
        "    csv_target = 94.94\n",
        "    gap = csv_target - overall_best['Accuracy']\n",
        "    print(f\"\\nCSV-FILTER COMPARISON:\")\n",
        "    print(f\"   Target: {csv_target}%\")\n",
        "    print(f\"   VICReg best: {overall_best['Accuracy']:.2f}%\")\n",
        "    print(f\"   Gap: {gap:.2f}%\")\n",
        "\n",
        "    if gap <= 0:\n",
        "        print(f\"   VICREG BEATS CSV-FILTER!\")\n",
        "    elif gap <= 2:\n",
        "        print(f\"   Very close! Excellent self-supervised performance.\")\n",
        "    else:\n",
        "        print(f\"   Good self-supervised performance on realistic data!\")\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "zdBQ14aTMen3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main experiments\n",
        "\n",
        "def run_all_vicreg_experiments():\n",
        "    \"\"\"Run all VICReg experiments with model saving\"\"\"\n",
        "\n",
        "    print(\"RUNNING ALL VICREG EXPERIMENTS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Load data\n",
        "    all_data = load_all_genomic_data()\n",
        "    splits = create_data_splits(all_data)\n",
        "\n",
        "    # Experiment configuration\n",
        "    class_setups = [2, 3]  # Binary and 3-class\n",
        "    split_names = list(splits.keys())\n",
        "\n",
        "    total_experiments = len(class_setups) * len(split_names)\n",
        "    print(f\"\\nPlanning {total_experiments} VICReg experiments:\")\n",
        "    print(f\"   Model: VICReg ResNet50x2\")\n",
        "    print(f\"   Class setups: {class_setups}\")\n",
        "    print(f\"   Data splits: {split_names}\")\n",
        "\n",
        "    # Run experiments\n",
        "    all_results = []\n",
        "\n",
        "    for num_classes in class_setups:\n",
        "        for split_name in split_names:\n",
        "            train_data = splits[split_name]['train']\n",
        "            test_data = splits[split_name]['test']\n",
        "\n",
        "            experiment_name = f\"vicreg_{num_classes}class_{split_name}\"\n",
        "\n",
        "            try:\n",
        "                result = train_vicreg_model(num_classes, train_data, test_data, experiment_name)\n",
        "                all_results.append(result)\n",
        "\n",
        "                # Save intermediate results\n",
        "                results_df = pd.DataFrame(all_results)\n",
        "                results_df.to_csv(os.path.join(SAVE_DIR, 'vicreg_results.csv'), index=False)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Failed {experiment_name}: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Clear memory\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Final summary\n",
        "    print(f\"\\nVICREG EXPERIMENT SUMMARY:\")\n",
        "    print(f\"   Completed: {len(all_results)}/{total_experiments}\")\n",
        "\n",
        "    if all_results:\n",
        "        results_df = pd.DataFrame(all_results)\n",
        "\n",
        "        print(f\"\\nVICREG RESULTS:\")\n",
        "        for _, result in results_df.iterrows():\n",
        "            print(f\"   {result['experiment']}: {result['best_test_acc']:.2f}% (AUC: {result['final_test_auc']:.3f})\")\n",
        "\n",
        "        overall_best = results_df.loc[results_df['best_test_acc'].idxmax()]\n",
        "        print(f\"\\nOVERALL BEST VICREG: {overall_best['best_test_acc']:.2f}%\")\n",
        "        print(f\"   Experiment: {overall_best['experiment']}\")\n",
        "        print(f\"   Saved at: {overall_best['model_path']}\")\n",
        "\n",
        "        # CSV-Filter comparison\n",
        "        csv_filter_target = 94.94\n",
        "        if overall_best['best_test_acc'] >= csv_filter_target:\n",
        "            print(f\"BEAT CSV-FILTER! (+{overall_best['best_test_acc'] - csv_filter_target:.2f}%)\")\n",
        "        else:\n",
        "            print(f\"Gap to CSV-Filter: {csv_filter_target - overall_best['best_test_acc']:.2f}%\")\n",
        "\n",
        "        # List all saved models\n",
        "        print(f\"\\nSAVED VICREG MODELS:\")\n",
        "        for _, result in results_df.iterrows():\n",
        "            if result['model_path']:\n",
        "                print(f\"   {result['experiment']}: {result['model_path']}\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "def compare_vicreg_to_resnet():\n",
        "    \"\"\"Compare VICReg results to ResNet baselines\"\"\"\n",
        "\n",
        "    print(\"COMPARING VICREG TO RESNET BASELINES\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Analyze VICReg results\n",
        "    vicreg_df = analyze_saved_vicreg_models()\n",
        "\n",
        "    if vicreg_df is None:\n",
        "        print(\"No VICReg results to compare\")\n",
        "        return\n",
        "\n",
        "    # Get best VICReg performance\n",
        "    best_vicreg = vicreg_df.nlargest(1, 'Accuracy').iloc[0]\n",
        "\n",
        "    print(f\"\\nPERFORMANCE COMPARISON:\")\n",
        "    print(f\"   Best VICReg: {best_vicreg['Accuracy']:.2f}% ({best_vicreg['Full_Name']})\")\n",
        "\n",
        "    # Note: ResNet comparison would require loading ResNet results\n",
        "    print(f\"   Self-supervised pre-training vs supervised ImageNet pre-training\")\n",
        "    print(f\"   VICReg uses learned representations from self-supervised learning\")\n",
        "\n",
        "    return vicreg_df"
      ],
      "metadata": {
        "id": "TtjVujQNMlce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oJsPCYML8Iw"
      },
      "outputs": [],
      "source": [
        "# Usage\n",
        "\n",
        "print(\"MAIN FUNCTIONS:\")\n",
        "print(\"   results = run_all_vicreg_experiments()\")\n",
        "print(\"   analysis_df = analyze_saved_vicreg_models()\")\n",
        "print(\"   comparison = compare_vicreg_to_resnet()\")\n",
        "print()\n",
        "print(\"MODEL LOADING:\")\n",
        "print(\"   model, checkpoint = load_saved_vicreg_model('/path/to/model.pth')\")\n",
        "print()\n",
        "print(\"EXPERIMENT DETAILS:\")\n",
        "print(\"   VICReg ResNet50x2 (Facebook self-supervised pre-trained)\")\n",
        "print(\"   2 class setups (binary TP/FP, 3-class FP/DEL/INS)\")\n",
        "print(\"   4 data splits (80/20 + 3 leave-one-genome-out)\")\n",
        "print(\"   = 8 total experiments\")\n",
        "print(\"   All models saved with full checkpoints\")\n",
        "\n",
        "# To run all experiments:\n",
        "# results = run_all_vicreg_experiments()\n",
        "\n",
        "# To analyze results:\n",
        "# analysis_df = analyze_saved_vicreg_models()\n",
        "\n",
        "# To compare with ResNet:\n",
        "# comparison = compare_vicreg_to_resnet()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = run_all_vicreg_experiments()"
      ],
      "metadata": {
        "id": "B-jpY5eNNcGX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}